<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>Recology</title>
		<description>An exploration of using R for ecology, evolution, and open science.</description>
		<link>http://schamberlain.github.com</link>
		
			<item>
				<title>Project Templates That Initialize A New Project With A Skeleton Automatically</title>
				<description>&lt;ul&gt;
&lt;li&gt;I have been using &lt;a href=&quot;http://projecttemplate.net/&quot;&gt;John Myles Whites ProjectTemplate R package&lt;/a&gt; for ages&lt;/li&gt;
&lt;li&gt;I really like the ease with which I can get up and running a new project&lt;/li&gt;
&lt;li&gt;and the ease with which I can pick up an old project and start adding new work&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Quote from John's first post&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;My inspiration for this approach comes from the rails command from
Ruby on Rails, which initializes a new Rails project with the proper
skeletal structure automatically. Also taken from Rails is
ProjectTemplateâ€™s approach of preferring convention over
configuration: the automatic data and library loading as well as the
automatic testing work out of the box because assumptions are made
about the directory structure and naming conventions that will be used
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/&quot;&gt;http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I dont know anything about RoR but this philosophy works really well for my R programming too&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;R Code&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;if(!require(ProjectTemplate)) install.packages(ProjectTemplate); require(ProjectTemplate)
setwd(&quot;~/projects&quot;)
create.project(&quot;my-project&quot;)
setwd('my-project')
dir()
##  [1] &quot;cache&quot;       &quot;config&quot;      &quot;data&quot;        &quot;diagnostics&quot; &quot;doc&quot;        
##  [6] &quot;graphs&quot;      &quot;lib&quot;         &quot;logs&quot;        &quot;munge&quot;       &quot;profiling&quot;  
## [11] &quot;README&quot;      &quot;reports&quot;     &quot;src&quot;         &quot;tests&quot;       &quot;TODO&quot;   
##### these are very sensible default directories to create a modular
##### analysis workflow.  See the project homepage for descriptions

# now all you need to do whenever you start a new day 
load.project()
# and your workspace will be recreated and any new data automagically analysed in
# the manner you want
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;Project Administration&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I;ve found that these directories do not work so well for the administration of my projects and so I put together a different set of automatic defaults&lt;/li&gt;
&lt;li&gt;Ive based it on the &lt;a href=&quot;http://ivanhanigan.github.io/2013/12/research-protocol-for-manitoba-centre-for-health-policy/&quot;&gt;University of Manitoba Centre for Health Policy&lt;/a&gt;- along with some other sources I can recall

&lt;h4&gt;The full set&lt;/h4&gt;

&lt;p&gt;  # A.Background      &lt;br/&gt;
  # B.Proposals
  # C.Approvals
  # D.Budget  &lt;br/&gt;
  # E.Datasets&lt;br/&gt;
  # F.Analysis&lt;br/&gt;
  # G.Literature      &lt;br/&gt;
  # H.Communication           &lt;br/&gt;
  # I.Correspondance  &lt;br/&gt;
  # J.Meetings&lt;br/&gt;
  # K.Completion      &lt;br/&gt;
  # ContactDetails.txt&lt;br/&gt;
  # README.md
  # TODO.txt&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;R Code: my subset&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;AdminTemplate &amp;lt;- function(rootdir = getwd()){
  setwd(rootdir)
  dir.create(file.path(rootdir,'01_planning'))
  dir.create(file.path(rootdir,'01_planning','proposal'))
  dir.create(file.path(rootdir,'01_planning','scheduling'))
  dir.create(file.path(rootdir,'02_budget'))
  dir.create(file.path(rootdir,'03_communication'))
  dir.create(file.path(rootdir,'04_reporting_and_meetings'))
  file.create(file.path(rootdir,'contact_details.txt'))
  file.create(file.path(rootdir,'README.md'))
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;hopefully by formalising some of these into my workflow I will find my projects easier to navigate through&lt;/li&gt;
&lt;li&gt;and pick up or put down as needed&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Sat Mar 29 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/03/project-templates-that-initialize-a-new-project-with-a-skeleton-automatically/</link>
			</item>
		
			<item>
				<title>long-term-climatology-contextual-data-for-ecological-research</title>
				<description>&lt;ul&gt;
&lt;li&gt;Studies of extreme weather events such as drought require long term climate data&lt;/li&gt;
&lt;li&gt;these are available at continental scale derived from&lt;/li&gt;
&lt;li&gt;observations from a network of weather stations that are interpolated to a surface&lt;/li&gt;
&lt;li&gt;I have been working on techniques with R and online resources (the Australian Water Availabilty Project AWAP) to make working with these long term climatology datasets easier.&lt;/li&gt;
&lt;li&gt;The package is in development at &lt;a href=&quot;https://github.com/swish-climate-impact-assessment/awaptools&quot;&gt;https://github.com/swish-climate-impact-assessment/awaptools&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Case Study&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;aim is need to look at seasonal rainfall means.&lt;/li&gt;
&lt;li&gt;first thing is to download the data (I'm also working on a Rstudio server to host these data, as a Virtual Lab).&lt;/li&gt;
&lt;li&gt;data = multiple years of monthly rainfall data in a raster grid format.&lt;/li&gt;
&lt;li&gt;aim = combine rainfall in a seasonal basis in one grid&lt;/li&gt;
&lt;li&gt;(i.e. M-J-J-A-S-O 1900, 1901 etc.) calculate mean of each cell.&lt;/li&gt;
&lt;li&gt;assumption1 = filenames have year, month embedded so they will be sorted in order when listed&lt;/li&gt;
&lt;li&gt;assumption2 = all months are available, from 1:12 for all years in&lt;/li&gt;
&lt;li&gt;study period&lt;/li&gt;
&lt;li&gt;notes:&lt;/li&gt;
&lt;li&gt;this requires the files are listed in the right order by name, and all months are present. might be better to use grep on the file name and strsplit/substr to extract the month identifier more precisely?&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/season_hot.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;I'm looking for collaboration on this!&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;I've been in contact with:&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/RationShop/rain_r/wiki/The-Rain-Project&quot;&gt;https://github.com/RationShop/rain_r/wiki/The-Rain-Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I apologise to windoze users but feel a bit like &lt;a href=&quot;http://librestats.com/2014/02/24/how-to-make-a-bad-password-with-r/&quot;&gt;this guy&lt;/a&gt; when recomending how to install:&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;quote:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;probably the easiest way to do this is to use
Hadley's devtools package.  Assuming you have devtools and my package's
dependencies.  If you're using Linux or the BSD's, this should just
work.  Welcome to the good life, player.  I think this will work out
of the box on a Mac.  I have no idea if this will work on Windows; how
you strange people get anything done amazes me.  At the least,
Im guessing you have to install Rtools first.  
You could also just source all the R scripts like 
some kind of barbarian
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# depends
require(swishdbtools)
if(!require(raster)) install.packages(&quot;raster&quot;, dependencies = T); require(raster)
if(!require(rgdal)) install.packages(&quot;rgdal&quot;, dependencies = T); require(rgdal)

# on linux can install direct, on windoze you configure Rtools
require(devtools)
install_github(&quot;awaptools&quot;, &quot;swish-climate-impact-assessment&quot;)
require(awaptools)

homedir &amp;lt;- &quot;~/data/AWAP_GRIDS/data&quot;
outdir &amp;lt;- &quot;~/data/AWAP_GRIDS/data-seasonal-vignette&quot;

# first make sure there are no left over files from previous runs
#oldfiles &amp;lt;- list.files(pattern = '.tif', full.names=T) 
#for(oldfile in oldfiles)
#{
#  print(oldfile)
#  file.remove(oldfile)
#}
################################################
setwd(homedir)

# local customisations
workdir  &amp;lt;- homedir
setwd(workdir)
# don't change this
years &amp;lt;- c(1900:2014)
lengthYears &amp;lt;- length(years)
# change this
startdate &amp;lt;- &quot;2013-01-01&quot;
enddate &amp;lt;- &quot;2014-01-31&quot;
# do
load_monthly(start_date = startdate, end_date = enddate)

# do
filelist &amp;lt;- dir(pattern = &quot;grid.Z$&quot;)
for(fname in filelist)
{
  #fname &amp;lt;- filelist[1]
  unzip_monthly(fname, aggregation_factor = 1)
  fin &amp;lt;- gsub(&quot;.grid.Z&quot;, &quot;.grid&quot;, fname)
  fout &amp;lt;- gsub(&quot;.grid.Z&quot;, &quot;.tif&quot;, fname)
  r &amp;lt;- raster(fin)
  writeRaster(r, fout, format=&quot;GTiff&quot;,  overwrite = TRUE)
  file.remove(fin)
}

cfiles &amp;lt;- list.files(pattern = '.tif', full.names=T) 
# loop thru
# NEED TO SET THE FILESOFSEASEON_I counter EACH TIME YOU start


for(season in c(&quot;hot&quot;, &quot;cool&quot;))
{
  # season &amp;lt;- &quot;hot&quot; # for labelling
  if(season == &quot;cool&quot;)
  {
    filesOfSeason_i &amp;lt;- c(5,6,7,8,9,10)  
    endat &amp;lt;- lengthYears
  } else {
    filesOfSeason_i &amp;lt;- c(11,12,13,14,15,16) 
    endat &amp;lt;- lengthYears - 1
  }

  for (year in 1:endat){ 
    ## setup for checking month 
    # year  &amp;lt;- 1 #endat


    ## checking
    print(cat(&quot;####################\n\n&quot;))
    print(cfiles[filesOfSeason_i])

    b &amp;lt;- brick(stack(cfiles[filesOfSeason_i])) 
    ## calculate mean 
    m &amp;lt;- mean(b) 
    ## checking 
    # image(m) 
    writeRaster(m, file.path(outdir,sprintf(&quot;season_%s_%s.tif&quot;, season, year)), drivername=&quot;GTiff&quot;)
    filesOfSeason_i &amp;lt;- filesOfSeason_i + 12
  } 
}

##### now we will overall average
setwd(outdir)
for(season in c(&quot;cool&quot;, &quot;hot&quot;))
{
  cfiles &amp;lt;- list.files(pattern = season, full.names=T)   
  print(cfiles)
  b &amp;lt;- brick(stack(cfiles)) 
  ## calculate mean 
  m &amp;lt;- mean(b) 
  ## checking 
  # image(m) 
  writeRaster(m, file.path(outdir,sprintf(&quot;season_%s.tif&quot;, season)), drivername=&quot;GTiff&quot;)
}

# qc
cool &amp;lt;- raster(&quot;season_cool.tif&quot;)
hot &amp;lt;- raster(&quot;season_hot.tif&quot;)
par(mfrow = c(2,1))
image(cool)
image(hot)

# just summer rainfall
png(&quot;season_hot.png&quot;)
image(hot)
dev.off()
&lt;/code&gt;&lt;/pre&gt;
</description>
				<published>Fri Feb 28 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/02/long-term-climatology-contextual-data-for-ecological-research/</link>
			</item>
		
			<item>
				<title>yearmon-class-and-interoperability-with-excel-and-access</title>
				<description>&lt;h4&gt;Toward a standard and unambiguous format for sharing Year-Month data&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I am working in a new job where we are recieving data from a lot of different groups&lt;/li&gt;
&lt;li&gt;we aim to review these datasets and then publish them for a wide audience of potential users&lt;/li&gt;
&lt;li&gt;therefore usability and interoperability is a key concern&lt;/li&gt;
&lt;li&gt;we recieved some data with Month and Year as Apr.12&lt;/li&gt;
&lt;li&gt;I know this is easy to convert to a date/time class with in R but wondered what a better format would be to recommend for our datasets to use to maximise utility downstream (especially for non R users)&lt;/li&gt;
&lt;li&gt;Apr.12 is assumed to be text in excel so need something else&lt;/li&gt;
&lt;li&gt;Apr-12 is assumed to be the twelfth of April this year (ie 12/4/2014)&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;In R the solution might be to use the zoo package&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;require(zoo)
as.yearmon(&quot;Apr.12&quot;, &quot;%b.%y&quot;)
# [1] &quot;Apr 2012&quot;

# other options abound
as.yearmon(&quot;apr12&quot;, &quot;%b%y&quot;)

# the default is YYYY-MM or similar
as.yearmon(&quot;2012-04&quot;)
as.yearmon(&quot;2012-4&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;So I went looking at how Excel and Access deal with this&lt;/li&gt;
&lt;li&gt;found that the best appeard to be MMM-YYYY in terms of how these software assume the data should look&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;as.yearmon(&quot;Apr-2012&quot;, &quot;%b-%Y&quot;)

# but will need to specify format because otherwise fails
as.yearmon(&quot;Apr-2012&quot;)
# NA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I recommend the MMM-YYYY option&lt;/li&gt;
&lt;li&gt;it is pretty good that in Excel it is assumed 1/04/2012&lt;/li&gt;
&lt;li&gt;and if MS access is set to date/time and format = mmm-yyyy is ok for data entry (but not importing)&lt;/li&gt;
&lt;li&gt;to import this use a shorttext type, then post-import, change to date/time with mmm-yyyy (the . failed)&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Thu Feb 27 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/02/yearmon-class-and-interoperability-with-excel-and-access/</link>
			</item>
		
			<item>
				<title>gantting-like-a-hacker</title>
				<description>&lt;h3&gt;Background&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html&quot;&gt;&quot;Blogging like a Hacker&quot;&lt;/a&gt; has become a paradigm for programmers who want to link their code to their blogs.&lt;/li&gt;
&lt;li&gt;I've followed this paradigm for a while to support my scientific projects, enhancing their transparency and reproducibility.&lt;/li&gt;
&lt;li&gt;I've started a new project where I need to also manage project management and planning (following &lt;a href=&quot;http://medepi.com/2012/02/05/project-mgmt/&quot;&gt;Tomas Aragon's tutorial&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;I propose that the same methods I use in scientific programming and blogging like a hacker can be used in &quot;Gantting like a Hacker&quot;&lt;/li&gt;
&lt;li&gt;The title for this post is also influenced by the poste over at &lt;a href=&quot;http://blog.geekmanager.co.uk/2007/05/02/using-the-best-plan-format/&quot;&gt;Geek | Manager&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;That post says taht &quot;Premature Gannting&quot; is the act of making a &quot;huge Gantt chart (often in MS Project).&quot;&lt;/li&gt;
&lt;li&gt;Gannting like a Hacker is doing this in a scripted environment, without relying on closed-source proprietry software such as the Windoze options.&lt;/li&gt;
&lt;li&gt;The community of bloggers (mostly geeks) who are following a style of blogging that originated with the invention of Jekyll, &lt;a href=&quot;http://tom.preston-werner.com/2008/11/17/blogging-like-a-hacker.html&quot;&gt;unveiled in this post by Tom Preston-Werner&lt;/a&gt;; GitHubâ€™s co-founder (aka mojombo).&lt;/li&gt;
&lt;li&gt;This experiment uses Taskjuggler and Emacs Orgmode&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Materials and Methods&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Use Ubuntu 12.04 Long Term Support (LTS)&lt;/li&gt;
&lt;li&gt;with Ruby&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Code:install task juggler&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;gem install taskjuggler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h3&gt;Gantt charts with Emacs Orgmode&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;I'm using an Emacs tool to use TaskJuggler to handle the task scheduling and creation of Gantt chart suitable for &lt;a href=&quot;http://orgmode.org/worg/org-tutorials/org-taskjuggler.html&quot;&gt;a Pointy-haired Boss&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;I hated using the Orgmode script to compile the parts of the Gantt chart so I wrote &lt;a href=&quot;https://raw.github.com/ivanhanigan/disentangle/gh-pages/gantt-tj3/gantt-tj3-build.R&quot;&gt;this R script&lt;/a&gt; to convert a spreadsheet into an Orgmode script&lt;/li&gt;
&lt;li&gt;the spreadsheet is organised in a fairly simple way shown below.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/gantt-chart-sheet.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Results&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;and executing my script will convert this into a Emacs orgmode file that will export to a taskjuggler file (use C-c C-e j) and viola!&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/gantt-chart.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Conclusions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;This simplifies the Orgmode taskjuggler creation&lt;/li&gt;
&lt;li&gt;A drawback is that it has to go through the Emacs export function.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Sat Feb 22 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/02/gantting-like-a-hacker/</link>
			</item>
		
			<item>
				<title>Aggregation Of Statistical Local Areas</title>
				<description>&lt;h2&gt;Reproducibility&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;A subset of the data and code used for this blog post is available at &lt;a href=&quot;https://github.com/ivanhanigan/aggregation-of-slas-or-sa2s&quot;&gt;https://github.com/ivanhanigan/aggregation-of-slas-or-sa2s&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Some parts of the data I used are not available due to shared Intellectual Property&lt;/li&gt;
&lt;li&gt;The spatial data and SEIFA Socioeconomic index data are publicly available from the Australian Bureau of Statistics&lt;/li&gt;
&lt;li&gt;The New Groups categories were generously contributed by John Glover of the Public Health Information Development Unit, The University of Adelaide.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The Aim is to aggregate Statistical Local Areas (SLAs, recently relabelled SA2) Australian Standard Geographical Classification (ASGC, recently relabelled ASGS) to achieve a greater level of privacy protection.
The rules to achieve a geography amenable to statistical comparisons are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;similar populations (around 20,000 to 30,000)&lt;/li&gt;
&lt;li&gt;homogenous Index of Relative Socioeconomic Disadvantage&lt;/li&gt;
&lt;li&gt;nested within the next level up in the ASGC/ASGS&lt;/li&gt;
&lt;li&gt;so that SSD (recently relabelled SA3) are not split.&lt;/li&gt;
&lt;li&gt;the SA2s can be aggregated through a process of assigning alike areas to groups, and reviewing/adjusting these assignments&lt;/li&gt;
&lt;li&gt;This document contains some suggestions for adjusting groupings to better reflect differences in the level of disadvantage, while still adhering to the rules outlined.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Results&lt;/h2&gt;

&lt;h3&gt;Data Prep&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The data were prepared as spatial files&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/aggregation-of-sa2s.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Assess proposed split in Belconnen&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;the proposed split in belconnen looks good&lt;/li&gt;
&lt;li&gt;This involves splitting Belconnen West (old SLA group) into two regions. The first generally has much higher proportion of individuals in a bottom quintile SES score&lt;/li&gt;
&lt;li&gt;Group 1 =  Belconnen/ Charnwood/ Florey/ Higgins/ Holt/ Latham&lt;/li&gt;
&lt;li&gt;Group 2 =  Flynn (ACT)/ Fraser/ Melba/ Spence&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/belco-split.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Assess the outliers&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;this can be done by identifying their component CCD SEIFA within new groups&lt;/li&gt;
&lt;li&gt;the seifa of CCD in outliers are compared to the others within their new groups&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/seifa-by-newgroups1.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;zoom in on croweded areas&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/seifa-by-newgroups1-2.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;!-- html table generated in R 3.0.2 by xtable 1.7-1 package --&gt;


&lt;!-- Tue Feb 18 22:03:04 2014 --&gt;


&lt;TABLE border=1&gt;
&lt;TR&gt; &lt;TH&gt;  &lt;/TH&gt; &lt;TH&gt; sa2_name.x &lt;/TH&gt; &lt;TH&gt; new_sa2_group &lt;/TH&gt; &lt;TH&gt; notes &lt;/TH&gt;  &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 12 &lt;/TD&gt; &lt;TD&gt; Bruce &lt;/TD&gt; &lt;TD&gt; Bruce/ Evatt/ Giralang/ Kaleen/ Lawson/ McKellar &lt;/TD&gt; &lt;TD&gt; higher than neighbours &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 14 &lt;/TD&gt; &lt;TD&gt; Campbell &lt;/TD&gt; &lt;TD&gt; Acton/ Braddon/ Campbell/ Civic/ Reid/ Turner &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 20 &lt;/TD&gt; &lt;TD&gt; Civic &lt;/TD&gt; &lt;TD&gt; Acton/ Braddon/ Campbell/ Civic/ Reid/ Turner &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 31 &lt;/TD&gt; &lt;TD&gt; Fadden &lt;/TD&gt; &lt;TD&gt; Fadden/ Gowrie (ACT)/ Macarthur/ Monash &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 32 &lt;/TD&gt; &lt;TD&gt; Farrer &lt;/TD&gt; &lt;TD&gt; Farrer/ Isaacs/ Mawson/ Pearce/ Torrens &lt;/TD&gt; &lt;TD&gt; higher than neighbours bar one ccd &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 37 &lt;/TD&gt; &lt;TD&gt; Forrest &lt;/TD&gt; &lt;TD&gt; Forrest/ Griffith (ACT)/ Kingston - Barton/ Narrabundah/ Red Hill (ACT) &lt;/TD&gt; &lt;TD&gt; higher than neighbours &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 60 &lt;/TD&gt; &lt;TD&gt; Isaacs &lt;/TD&gt; &lt;TD&gt; Farrer/ Isaacs/ Mawson/ Pearce/ Torrens &lt;/TD&gt; &lt;TD&gt; higher than neighbours bar one ccd &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 64 &lt;/TD&gt; &lt;TD&gt; Kingston - Barton &lt;/TD&gt; &lt;TD&gt; Forrest/ Griffith (ACT)/ Kingston - Barton/ Narrabundah/ Red Hill (ACT) &lt;/TD&gt; &lt;TD&gt; higher than neighbours &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 71 &lt;/TD&gt; &lt;TD&gt; Macarthur &lt;/TD&gt; &lt;TD&gt; Fadden/ Gowrie (ACT)/ Macarthur/ Monash &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 73 &lt;/TD&gt; &lt;TD&gt; Macquarie &lt;/TD&gt; &lt;TD&gt; Aranda/ Cook/ Hawker/ Macquarie/ Page/ Scullin/ Weetangera &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 87 &lt;/TD&gt; &lt;TD&gt; O'Malley &lt;/TD&gt; &lt;TD&gt; Chifley/ Lyons (ACT)/ O'Malley/ Phillip &lt;/TD&gt; &lt;TD&gt; higher than neighbours &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 89 &lt;/TD&gt; &lt;TD&gt; Page &lt;/TD&gt; &lt;TD&gt; Aranda/ Cook/ Hawker/ Macquarie/ Page/ Scullin/ Weetangera &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; 98 &lt;/TD&gt; &lt;TD&gt; Scullin &lt;/TD&gt; &lt;TD&gt; Aranda/ Cook/ Hawker/ Macquarie/ Page/ Scullin/ Weetangera &lt;/TD&gt; &lt;TD&gt; ok &lt;/TD&gt; &lt;/TR&gt;
   &lt;/TABLE&gt;


&lt;h3&gt;Investigating areas: eg the Kingston - Barton area&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;we can zoom in on some of these areas&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/kingston-barton.png&quot; alt=&quot;alttext&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;Basically, the problem comes from public housing policies in Canberra which distorts the effect of the housing market and land values in segregating rich from poor. Essentially, there are highly advantaged suburbs with pockets of disadvantaged public housing.&lt;/p&gt;

&lt;p&gt;Other 'problematic' features re this are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;proximity to ornamental lakes&lt;/li&gt;
&lt;li&gt;proximity to urban green space&lt;/li&gt;
&lt;li&gt;proximity to rural residential hubs (walaroo road?  hall?).  This is a bit of a reverse statement -- but different to 'distance from urban centre'&lt;/li&gt;
&lt;li&gt;elevation, especially with a view.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Potentially the issue is going to be that this can't be solved if you want to maintain SA2 as the base level - the distinctions are going to be at an SA1 or even mesh block level.&lt;/p&gt;
</description>
				<published>Tue Feb 18 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/02/aggregation-of-statistical-local-areas/</link>
			</item>
		
			<item>
				<title>Template Reproducible Research with R TEX and Sweave</title>
				<description>&lt;ul&gt;
&lt;li&gt;Last year I wrote to a Professor to let them know some numbers that quantified their effect estimate (computed be exponentiating their beta coefficient) described in their results section was inconsistent with the numbers in their table (the raw coefficients).&lt;/li&gt;
&lt;li&gt;Happily the recalculation showed that they had underestimated the effect size and their conclusions were not wrong, but erroneously conservative.&lt;/li&gt;
&lt;li&gt;Previously I would use Sweave documents to keep track of all my calculations, but I was still copy-and-pasting the key numbers into the text.&lt;/li&gt;
&lt;li&gt;I've become more interested now in using Inline R Outputs (called Sexpr - S expressions)&lt;/li&gt;
&lt;li&gt;This is also the first time I've created a report using the Palatino font, on the advice of a new colleague of mine.&lt;/li&gt;
&lt;li&gt;I popped up a &lt;a href=&quot;https://github.com/ivanhanigan/DataDocumentation&quot;&gt;Github repo with a Sweave template for Reproducible Reports with a few notes I made&lt;/a&gt;.  Which looks like&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/sexpr.png&quot; alt=&quot;/images/sexpr.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&quot;https://github.com/ivanhanigan/DataDocumentation/blob/master/src/sexpr.pdf&quot;&gt;PDF output is here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&quot;https://github.com/ivanhanigan/DataDocumentation/blob/master/src/sexpr.Rnw&quot;&gt;Sweave file is here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Wed Feb 12 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/02/template-reproducible-research-with-r-tex-and-sweave/</link>
			</item>
		
			<item>
				<title>studygroup-review-of-tree-based-models-for-testing-multiple-working-hypotheses</title>
				<description>&lt;p&gt;Yesterday I had the opportunity to review the Tree based modelling methods we are implementing in a study I'm working on at the moment.
I based the discussion on &lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1080/00330124.2012.724347&quot;&gt;a paper from 2012&lt;/a&gt;, along with &lt;a href=&quot;/pdfs/TreeModelNotes.pdf&quot;&gt;some notes I have made related to the use of these methods in our context&lt;/a&gt;.
I had an hour and a half with a couple of senior statisticians and a bunch of sociologists at the study group yesterday.&lt;/p&gt;

&lt;h4&gt;My main question for the group was:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;What do you think of the proposition that these models are suitable for &quot;studies that test hypotheses generated from multiple theories&quot;?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The statisticians where underwhelmed by the Cutts study, but thought the stats method was &quot;neat&quot; and one had not heard of tree models before (!).&lt;/p&gt;

&lt;h4&gt;Key outcomes of that session were:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First stage PCA&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Q: did they need to do the PCA first stage to either a) reduce the the large number of potentially collinear variables or b) to control for measurement error?&lt;/li&gt;
&lt;li&gt;A: No they didn't need the PCA.  The large number, collinearity and measurement efficacy are dealt with by the tree based methods (ie cross-validation on steroids, grouping primary and surrogate splits, etc).  Also the trees have an advantage with the large number of predictors in that they are non-parametric and able to automatically detect interactions whereas PCA is parametric and typically assumes linearity. (Note that I saw Steve afterward and he is still not convinced.  Maybe he will respond to this with some description of the reason why not?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rescaling the variables&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Q: Did they need to centre each variable on the grand sample mean so that the relative weight of each variable was even?&lt;/li&gt;
&lt;li&gt;A: No the tree models are not effected by this, and it reduced the interpret-ability of the decision tree graphic.  The PCA is effected, however, and maybe that is why they did it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Multiple working hypotheses&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Q: What do you think of the Cutts et al proposition that these models are suitable for &quot;studies that test hypotheses generated from multiple theories&quot;?&lt;/li&gt;
&lt;li&gt;A: It is a promising approach.  Not clear from this study if it is successful but the proposition is plausible.  It has more of a chance than the General Linear Model approach which cannot (this point was made categorically by one of the statisticians).  It will be important to be very clear about what exactly each of the &quot;Theories&quot; are predicting, so that the explanatory power attributable to those variables from one &quot;theory&quot; can be compared with that of the other theories.  The ability to uncover complex interactions is very attractive (extrovert/introvert personality type interacting with group demographics etc) but it also increases the potential for spurious results (and 'chasing the noise') ergo the need to base inferences on what the theories predict, not just on what the data reveal.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In general we thought that authors had overdone the stats.  It showed what 'could' be done with trees and forests, but possibly not what 'should' be done.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Is the A3 variable really missing from ctree output but dominant in the randomForest in Figure3?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;when another group I'm in reviewed it last year it was noted as odd that fig3 has A3 most important in randomforest but does not appear in ctree. At the time I thought this might be due to the cross validation like in the rpart or tree package, but it turns out that ctree does not do that....&lt;/li&gt;
&lt;li&gt;Mislabelling is a possibility as these graphics appear to be edited from the default produced by the 'party' package.&lt;/li&gt;
&lt;li&gt;However, it also reasonable that these results could be correct. ctree (and rpart, tree, etc.) use greedy algorithms, meaning that the best local split is used even if this is suboptimal globally.&lt;/li&gt;
&lt;li&gt;Basically there are algorithmic reasons that this might be a true difference between ctree and randomforest.  It might just have been the way the cookie crumbled for the ctree's best local split which may not have survived through the randomForest's  thousands of iterations.&lt;/li&gt;
&lt;li&gt;But on page 569 they do say &quot;total knowledge is lowest among those whod do not think that they are empowered and are unaware of information sources&quot; which implies to me that the top or left-most node might be mis-labelled I3 when it is actually A3.&lt;/li&gt;
&lt;li&gt;this would give the appropriate left most box plot (ie I3 &amp;lt;= -0.22 &amp;amp; A3 &amp;lt;= -0.64 gives lowest total knowledge??)&lt;/li&gt;
&lt;li&gt;at the group yesterday people also generally suspected mislabelling, given the dominance of A3 in randomforest.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Thu Jan 23 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/01/studygroup-review-of-tree-based-models-for-testing-multiple-working-hypotheses/</link>
			</item>
		
			<item>
				<title>Morpho And R-EML Use Case Marsupial mulgara Dasycercus cristicauda</title>
				<description>&lt;h1&gt;Aim&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;https://github.com/ropensci/EML&quot;&gt;EML R package&lt;/a&gt; uses the Ecological Metadata Language (EML) approach that allows archiving of very heterogeneous data without having to standardize everything into a narrow and pre-defined syntax.&lt;/li&gt;
&lt;li&gt;XML files in specificed schemas involve strict criteria and are thus best generated by software.&lt;/li&gt;
&lt;li&gt;Morpho is an application that provides another GUI based method of generating EML but is a rather tedious tool for generating EML files. Unfortunately, without the ability to script inputs or automatically detect existing data structures, we are forced through the rather arduous process of adding all metadata annotation each time.&lt;/li&gt;
&lt;li&gt;The aim of this experiment is to use the EML package to create some advanced metadata quickly and then finish this off with Morpho, using &lt;a href=&quot;http://en.wikipedia.org/wiki/Boilerplate_code&quot;&gt;&quot;boilerplate code&quot;&lt;/a&gt; wherever possible.&lt;/li&gt;
&lt;li&gt;this builds on my previous post &lt;a href=&quot;http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry&quot;&gt;http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Background&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;I am basically very lazy when it comes to entering metadata and when I use the Morpho package for metadata data entry I get frustrated with having to step through ever SINGLE variable and use the drop down menus etc to describe them as essentially &quot;number&quot; or &quot;text&quot;&lt;/li&gt;
&lt;li&gt;A big reason I like Morpho is because Metacat is a great data portal and Kepler is a promising scientific workflow tool, and all three are produced by the same group so it would be great to get them working together...&lt;/li&gt;
&lt;li&gt;Morpho and Metacat are open source software designed to host all kinds of ecological data. More information about it can be found &lt;a href=&quot;http://knb.ecoinformatics.org/index.jsp&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;More info about the Metacat Data Portal System is &lt;a href=&quot;https://knb.ecoinformatics.org/knb/docs/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For technical reasons, I'm running an older version of the Morpho software because I'm working with an older version of the  Metacat portal software and so are also constrained to running the older Morpho version too (but will be upgrading soon).&lt;/li&gt;
&lt;li&gt;You might want to look at the background of the Ecological Metadata Language (EML) standard.  I like this page &lt;a href=&quot;http://carlboettiger.info/2013/06/23/notes-on-leveraging-the-ecological-markup-language.html&quot;&gt;http://carlboettiger.info/2013/06/23/notes-on-leveraging-the-ecological-markup-language.html&lt;/a&gt; along with the references he cites at the bottom.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Material&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;To tie this experiment back to something that is actually useful for a scientist, I will use the field-based example data on the effects on mulgara of removing spinifex, from:&lt;/p&gt;

&lt;p&gt;  McCarthy, M. a., &amp;amp; Masters, P. (2005). Profiting from prior
  information in Bayesian analyses of ecological data. Journal of
  Applied Ecology, 42(6),
  1012â€“1019. doi:10.1111/j.1365-2664.2005.01101.x&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Brief description is:&lt;/p&gt;

&lt;p&gt;  an experimental manipulation of habitat was conducted by Masters,
  Dickman &amp;amp; Crowther (2003) in which vegetation cover of a site in
  arid inland Australia was reduced and the response of the mammal
  fauna monitored.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;you can find the data in the download file from &lt;a href=&quot;http://www.nceas.ucsb.edu/~mccarthy/research.html&quot;&gt;the &quot;Code for analysing the mulgara experiment&quot; from here&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;I first checked that these data aren;t already on &lt;a href=&quot;https://knb.ecoinformatics.org/m/&quot;&gt;the KNB repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I searched for Marsupial, Australia, Mulgara and etc, finding no hits.&lt;/li&gt;
&lt;li&gt;We will assume that these data are not already published there.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Methods&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Step one install the github version of EML and &lt;a href=&quot;http://ivanhanigan.github.io/2013/10/morpho-and-reml-streamline-the-process-of-metadata-entry/#sec-1-9&quot;&gt;a function I wrote for this a while back&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Note that I made a few changes since that post &lt;a href=&quot;https://github.com/ivanhanigan/disentangle/blob/master/R/reml_boilerplate.r&quot;&gt;https://github.com/ivanhanigan/disentangle/blob/master/R/reml_boilerplate.r&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# func
library(&quot;devtools&quot;)
install_github(&quot;EML&quot;, &quot;ropensci&quot;)       
library(&quot;EML&quot;)
install_github(&quot;disentangle&quot;, &quot;ivanhanigan&quot;)       
library(&quot;disentangle&quot;)

# load                                                                    
datatext &amp;lt;- 'Treat, Before, After1, After2
0,  2.833213344,    1.609437912,    2.48490665
0,  1.791759469,    2.197224577,    2.079441542
0,  3.044522438,    2.708050201,    3.135494216
0,  2.772588722,    1.791759469,    2.197224577
0,  1.098612289,    1.609437912,    2.63905733
1,  2.944438979,    0.693147181,    1.791759469
1,  2.564949357,    0.693147181,    1.791759469
1,  2.564949357,    1.609437912,    1.609437912
1,  0.693147181,    1.098612289,    1.098612289
1,  1.609437912,    0,      1.098612289'
analyte &amp;lt;- read.csv(textConnection(datatext))

# check
analyte

# do
## from a work dir with a subdir for data
write.csv(analyte, &quot;data/mulgara.csv&quot;, row.names = F)
reml_boilerplate(
  data_set = analyte
  ,
  created_by = &quot;Ivan Hanigan &amp;lt;ivanhanigan@gmail.com&amp;gt;&quot;
  ,
  data_dir = &quot;data&quot;
  ,
  titl = &quot;mulgara&quot;
  ,
  desc = &quot;Experimental data: effect of cover reduction on mulgara Dasycercus cristicauda&quot;
  )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;ul&gt;
&lt;li&gt;Now open morpho and under file &gt; import browse to this  data directory and import.&lt;/li&gt;
&lt;li&gt;Got several warnings, about unable to display data, and an older version that could be updated&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Results&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Result does not display  in morpho&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;img src=&quot;/images/mulgara-morpho-import.png&quot; alt=&quot;mulgara-morpho-import.png&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;Discussion&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;There is something different about the way the EML R package writes the data and what Morpho 1.8 is expecting.&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Further research is required.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Tue Jan 21 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/01/morpho-and-reml-use-case-marsupial-mulgara-dasycercus-cristicauda/</link>
			</item>
		
			<item>
				<title>Github, gh-pages and disqus comments</title>
				<description>&lt;p&gt;A while ago I posted about &lt;a href=&quot;http://ivanhanigan.github.io/2013/11/sharing-and-extending-research-protocols/&quot;&gt;sharing-and-extending-research-protocols&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I've started a new experiment for hosting a discussion around issues, suggesting new issues, agreeing on solutions, toward an agreement on methods that could become a protocol:
&lt;a href=&quot;http://ivanhanigan.github.com/datasharing&quot;&gt;http://ivanhanigan.github.com/datasharing&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I forked the material from the original author Jeff Leek &lt;a href=&quot;https://github.com/jtleek/datasharing/network&quot;&gt;https://github.com/jtleek/datasharing/network&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The goal of my experiment is something along the lines of the Prometheus Wiki &lt;a href=&quot;http://prometheuswiki.publish.csiro.au&quot;&gt;http://prometheuswiki.publish.csiro.au&lt;/a&gt;â€‹ which is a site for sharing research protocols. That idea is to give people a place to post research protocols since everyone develops them and then mentions them in papers but they rarely make it online in a usable format.&lt;/p&gt;

&lt;p&gt;But I was talking with an user of that and he complained it lacked a kind of &quot;dynamic collaboration with a front-end markup system in place that was integrated with a good website-type backend&quot;.  This is what the github site might be able to do.&lt;/p&gt;

&lt;p&gt;I discussed with a colleague and he seemed to be receptive to experimenting with this, so long as it was not more cumbersome than:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;shooting off an email with a list of points or&lt;/li&gt;
&lt;li&gt;catching me in the tea room and saying &quot;by the way - missing values should never be -9999&quot;&lt;/li&gt;
&lt;li&gt;and then these being copied into a master document we all share.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The system I'm using in the proposed experiment uses the hi-tech tools gh-pages with disqus comments.  This let's:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;casual users chip in their two cents worth quickly via the  comments,&lt;/li&gt;
&lt;li&gt;users can vote up or vote down other peoples comments,&lt;/li&gt;
&lt;li&gt;track the discussion via their emails (if they choose that option),&lt;/li&gt;
&lt;li&gt;but those wanting  deeper involvement can fork and edit the pages and then submit pull  requests to the lead author.&lt;/li&gt;
&lt;li&gt;Github's wiki and issues tracking functionality also could be used for serious development.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Tue Jan 14 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/01/github-gh-pages-and-disqus-commentsdatasharing/</link>
			</item>
		
			<item>
				<title>cwt-lter-data-submission-template-critique</title>
				<description>&lt;ul&gt;
&lt;li&gt;A colleague sent me the cwt_data_subm_template_2013.xls today&lt;/li&gt;
&lt;li&gt;LTER is The U.S. Long-Term Ecological Research (LTER) network&lt;/li&gt;
&lt;li&gt;I made the following notes, this is not intended to be a nasty critique&lt;/li&gt;
&lt;li&gt;The following is a few Frank and Fearless comments I'll be using to compare the pros and cons of a variety of data documentation approaches&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Critique&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;opened first on windows, saw comments on cells with instructions&lt;/li&gt;
&lt;li&gt;opened next on linux with libreOffice and comments are gone&lt;/li&gt;
&lt;li&gt;opened at the last tab (split in two for no reason?)&lt;/li&gt;
&lt;li&gt;noticed recommended name &quot;GCE site&quot; = Site, otherwise &quot;permanent plot&quot; =      Plot?&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nsmn1.uh.edu/steve/research/gce/gce.htm&quot;&gt;GCE = Georgia Coastal Ecosystems LTER program&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;flip to first tab, point 4 suggests there is some export functionality I cannot see (a VBA script?)&lt;/li&gt;
&lt;li&gt;cell 11 a    NOTE: When submitting updated metadata or re-using templates please highlight fields with modified contents in yellow&lt;/li&gt;
&lt;li&gt;and use glitter pen???&lt;/li&gt;
&lt;li&gt;personnell tab OK&lt;/li&gt;
&lt;li&gt;instrumentation, variable measured is free text. ok but for eg &quot;max temp&quot;, &quot;temperature maxima&quot;, &quot;maximum temperature (c)&quot; &quot;maximum temperature in 24 hours after 9am local time in degrees&quot; etc&lt;/li&gt;
&lt;li&gt;too wide, last column was off my wide screen! noticed wasted real estate in column A&lt;/li&gt;
&lt;li&gt;tabular data &quot;â€“  Paste or enter your data values into the 'Values' section (white cells), starting with the indicated cell&quot;&lt;/li&gt;
&lt;li&gt;this is an invitation for clerical error!
â€“  Fill in missing values in the table with NaN (not a number), including text fields, and do not skip columns&lt;/li&gt;
&lt;li&gt;but what about missing values imbued with other meanings (NA = not observed, censored etc)?&lt;/li&gt;
&lt;li&gt;ask users to format digit rounding in Excel?? oh no&lt;/li&gt;
&lt;li&gt;old excel users may still be restricted to 65,536 rows by 256 columns.&lt;/li&gt;
&lt;li&gt;non tabular sheet is ok&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Tue Jan 07 00:00:00 +1100 2014</published>
				<link>http://schamberlain.github.com/2014/01/cwt-lter-data-submission-template-critique/</link>
			</item>
		
	</channel>
</rss>