<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>Recology</title>
		<description>An exploration of using R for ecology, evolution, and open science.</description>
		<link>http://schamberlain.github.com</link>
		
			<item>
				<title>introduction-to-ons-theory-and-practice</title>
				<description>&lt;p&gt;The reasons why ONS is so appealing to me can be broken into two parts.  The first is about the problems which it solves, the second is about the benefits it might bring.&lt;/p&gt;

&lt;h4&gt;The Problems&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Identifying errors (either from miscalculations or from methodological mistakes)&lt;/li&gt;
&lt;li&gt;Uncovering fraud&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;The Benefits&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Sharing interests and skills&lt;/li&gt;
&lt;li&gt;Quickly finding out about new discoveries and failures&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;These benefits come from the enhanced potential for theoretical discussions and sharing ideas.  This is especially valuable around difficult theories, unknown issues or esoteric theories that are known only to a specialist in a field.&lt;/p&gt;
</description>
				<published>Mon Sep 23 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/introduction-to-ons-theory-and-practice/</link>
			</item>
		
			<item>
				<title>workflow-flowcharts-update</title>
				<description>&lt;h1&gt;Workflow flowcharts - Update&lt;/h1&gt;

&lt;p&gt;A while back I posted about my work with the Rgraphviz toolbox toward a wrapper function that will allow me to track the connections between chunks of my code as I write it.
This update includes notes from a discussion I had with Keith about this.&lt;/p&gt;

&lt;h4&gt;Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;require(disentangle)
nodes &amp;lt;- newnode(&quot;NAME&quot;, &quot;INPUT&quot;, &quot;OUTPUT&quot;, newgraph =T)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<published>Sun Sep 22 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/workflow-flowcharts-update/</link>
			</item>
		
			<item>
				<title>using-orgmode-and-jekyll-for-open-notebook</title>
				<description>&lt;h1&gt;Using Orgmode and Jekyll for Open Notebook&lt;/h1&gt;

&lt;p&gt;Orgmode is a great notebook tool because it allows the coding, evaluation and documentation all in one.  I also want to use it to send the documentation to my blog as an Open Notebook.&lt;/p&gt;

&lt;p&gt;If starting again I'd look into this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://orgmode.org/worg/org-tutorials/org-jekyll.html&quot;&gt;http://orgmode.org/worg/org-tutorials/org-jekyll.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;But as it is I already put a lot of work into configuring a jekyll blog I cloned from Scott Chamberlain over at ROpenSci and I will just use orgmode to publish the posts related to each project, tagged as 'categories'.&lt;/p&gt;

&lt;p&gt;But here is a problem I just found out how to solve.  For a long time I thought that because github disabled ruby plugins that the automatic generate categories index pages was broken.  Luckily Charlie Park has written up the following solution and this seems to have worked for me today:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://charliepark.org/tags-in-jekyll/&quot;&gt;http://charliepark.org/tags-in-jekyll/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://charliepark.org/jekyll-with-plugins/&quot;&gt;http://charliepark.org/jekyll-with-plugins/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Cheers!&lt;/p&gt;
</description>
				<published>Sun Sep 22 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/using-orgmode-and-jekyll-for-open-notebook/</link>
			</item>
		
			<item>
				<title>transformational-adaptation</title>
				<description>&lt;p&gt;Energymark is about transformational adaptations as opposed to incremental adaptation..&lt;/p&gt;
</description>
				<published>Sun Sep 22 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/transformational-adaptation/</link>
			</item>
		
			<item>
				<title>toward-a-unified-ecology-dataset</title>
				<description>&lt;h1&gt;Ecology datasets&lt;/h1&gt;

&lt;p&gt;These are my notes from a meeting that Kathryn and I had with a group of Ecologists at the ANU (primarily Luciana Porforio and Nasreen Khan).  We asked them to discuss how they search for and use Ecology datasets, especially how to best package up the parts of an ecological field data collection (ie weather, vegetation, biodiversity, soils, topography etc).&lt;/p&gt;

&lt;p&gt;Lu started off the discussion by stating that the most important thing to acknowledge is that every ecologist will start off with a main research question and then search for data that will address their specific research question.  It is difficult to work from a 'top-down' perspective that hopes to pre-empt the range of possible questions.  Lu felt that it may therefore be best to just keep all the data together in the biggest bundle that is possible and the end user can pick it apart once downloaded.&lt;/p&gt;

&lt;p&gt;We explained that LTERN datasets can be quite expansive with many dimensions and it seemed preferable to at least untangle the main 'themes' for packaging up.&lt;/p&gt;

&lt;p&gt;Nasreen pointed out that there is always a protocol for how data are collected and this should give the data collection it's structure.  However I felt that ecology collections are so diverse they have been made (by necessity) very flexible and specific to the needs of the individual plot network.  Therefore generalisations across data collections are very hard to make (apart from easy things like &quot;weather&quot; or &quot;aboveground dead biomass&quot;).&lt;/p&gt;

&lt;h1&gt;Toward a Unified Ecology&lt;/h1&gt;

&lt;p&gt;I always fall back on the text book &quot;Toward a Unified Ecology: Timothy F. H. Allen, Thomas W. Hoekstra 1992&quot;.  I wondered if it can guide us?  On pages 42-53 they describe the following framework and use the image below (the letters in the middle disc correspond to the criteria ie O = Organism).  In this framework it is possible to summarise ANY ecological study as they ALWAYS incorporate these scale-independent criteria:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Organism: genetic integrity, discrete body, autonomy from other organisms&lt;/li&gt;
&lt;li&gt;Population: relative similarity within the group&lt;/li&gt;
&lt;li&gt;Community: inter-species competition, interference, mutualism&lt;/li&gt;
&lt;li&gt;Ecosystem: biotic and abiotic interactions&lt;/li&gt;
&lt;li&gt;Landscape: spatial structure/contiguity&lt;/li&gt;
&lt;li&gt;Biome: characteristic physiognomy, disturbance and climate&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I thought that if these dimensions were identified in a data collection first then they might become the discrete packages by which each plot network publishes their collection?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/datadoco-layercake.png&quot; alt=&quot;datadoco-layercake.png&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;Aekos&lt;/h1&gt;

&lt;p&gt;Over at &lt;a href=&quot;http://www.aekos.org.au/why_aekos#diversity&quot;&gt;AEKOS&lt;/a&gt; they have a similar conceptual framework&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Observations can range from that of individual organisms and
interactions, through to populations, communities, ecosystems and
across broad global landscapes.
&lt;/code&gt;&lt;/pre&gt;

&lt;h1&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;This is an open issue.  More discussions are needed internally for the Data Custodians.&lt;/p&gt;

&lt;p&gt;Lu also pointed out that the end users are the key stakeholders and perhaps more input from them (via surveys and workshops?) is needed?&lt;/p&gt;
</description>
				<published>Fri Sep 20 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/toward-a-unified-ecology-dataset/</link>
			</item>
		
			<item>
				<title>energymark</title>
				<description>&lt;h1&gt;Energymark&lt;/h1&gt;
</description>
				<published>Thu Sep 19 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/energymark/</link>
			</item>
		
			<item>
				<title>pumilio-bushfm-test-dev-prod</title>
				<description>&lt;h1&gt;Testing the pumilio-bushfm-test-dev-prod build process, in an Open Notebook&lt;/h1&gt;

&lt;h4&gt;Aims:&lt;/h4&gt;

&lt;p&gt;It was suggested I could document the pumilio test build as an OpenNotebook.
I imagined that I could link this blog to github repo and doco hosted on gh-pages.&lt;/p&gt;

&lt;h4&gt;Methods:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;For ie the emacs html output now goes to &lt;a href=&quot;http://ivanhanigan.github.io/pumilio-bushfm/&quot;&gt;http://ivanhanigan.github.io/pumilio-bushfm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;then collaborators can clone/fork &lt;a href=&quot;https://github.com/ivanhanigan/pumilio-bushfm&quot;&gt;https://github.com/ivanhanigan/pumilio-bushfm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;and comment/complain at &lt;a href=&quot;https://github.com/ivanhanigan/pumilio-bushfm/wiki&quot;&gt;https://github.com/ivanhanigan/pumilio-bushfm/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Results:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I did a test build a month ago on an old laptop sitting around, then rebuilt on the Nectar cloud&lt;/li&gt;
&lt;li&gt;Unfortunately I didn't realise that the Nectar VM had mounted /var on to the smaller root partition (the 40GB 2nd disk is on /mnt).&lt;/li&gt;
&lt;li&gt;then when I tried to upload a big sound file it broke :-(&lt;/li&gt;
&lt;li&gt;I did a bit of reading and whilst I began thinking I'd just need to move the mysql datadir via&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sudo nano /etc/mysql/my.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;BUT&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;it actually looks like there is a WAV and MP3 file under /var/www/pumilio-2...&lt;/li&gt;
&lt;li&gt;so I think I can &lt;a href=&quot;http://askubuntu.com/questions/39536/how-can-i-store-var-on-a-separate-partition&quot;&gt;just remount /var&lt;/a&gt; onto the larger /mnt secondary disk.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Wed Sep 18 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/pumilio-bushfm-test-dev-prod/</link>
			</item>
		
			<item>
				<title>Starting my Open Notebook Science Blog</title>
				<description>&lt;p&gt;Many examples are emerging of scientists who are transitioning to a
much more open model of research.  This is in part externally driven
by funding bodies (such as the Aussie Research Council asking for deposit of funded data and papers) and journals
(&lt;a href=&quot;http://www.nature.com/ng/journal/v45/n5/full/ng.2621.html&quot;&gt;ie. Nature journals removing length restrictions on Methods sections.&lt;/a&gt;). Also the increased value being placed on transparency of reproducible analysis to safeguard against error and fraud is becoming an internal driver within science communities.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Open_Notebook_Science&quot;&gt;Open Notebook Science&lt;/a&gt;
(ONS) style is an extreme of transparent approaches to research.
According to the wikipedia page it is the &quot;practice of making the
entire primary record of a research project publicly available online
as it is recorded&quot;.&lt;/p&gt;

&lt;p&gt;That's pretty extreme!  In my view a lot of stuff in the research project should probably be archived quickly and left to rot.&lt;/p&gt;

&lt;p&gt;I like the range of options available.  I think I'll go for &lt;a href=&quot;http://onsclaims.wikispaces.com/&quot;&gt;SCD or &quot;Seclected Content / Delayed&quot;&lt;/a&gt; and show their image below.  In this model a portion of the open notebook and associated supporting raw data are available after some delay. I'll try to use this blog for weekly updates on progress for each project, and provide links off my 'Open Notebook' and 'Software' Tabs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ONS-SCD.png&quot; alt=&quot;ONS-SCD.png&quot; /&gt;&lt;/p&gt;
</description>
				<published>Fri Sep 13 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/09/ons/</link>
			</item>
		
			<item>
				<title>Worflow flowcharts</title>
				<description>&lt;h2&gt;What is the issue&lt;/h2&gt;

&lt;p&gt;Most people seem to collect multiple datasets together in a single spot that can be split into 2 or more separate data packages.  I think this is a natural set up from an analysts perspective, where the results of multiple steps accumulate as 'stepping stones' toward the file they end up analysing.&lt;/p&gt;

&lt;p&gt;I was first taught GIS by Isabelle Balzer at Ecowise Environmental Services in Canberra.  She showed me the method of keeping a table (sticky-taped to the desk!) of all the files and transformations that were going on. This was a method that didn't allow any multitasking!  I call this the 'Balzerian Method' (I am sure others used it before Isabelle, but I think Balzerian is a great word).&lt;/p&gt;

&lt;p&gt;I think the data wharehouse at my work is an example, and probably we'll find the key challenge for big data will be for analysts to disentangle their own filing systems.&lt;/p&gt;

&lt;p&gt;In my experience the way people store research data is often one (or a couple, or all) of these three types:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a database with heaps of tables and views&lt;/li&gt;
&lt;li&gt;a directory (and sub-directories) with heaps of files&lt;/li&gt;
&lt;li&gt;a spreadsheet workbook with heaps of sheets (and links to other workbooks)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I am developing a tool based on the open source graphviz softawre. The tool I am developing addresses the challenge of graphing the links between these sequential steps.&lt;/p&gt;

&lt;h4&gt;Code:introducing newnode&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# NB this only works easily on linux
require(devtools)
install_github(&quot;disentangle&quot;, &quot;ivanhanigan&quot;)
require(disentangle)
# the core of the tool is Rgraphviz, I just built a wrapper function
# to add newnodes to a graph of nodes
# always start with (newgraph = T) because the newnode function ADDS
# nodes to a graph, unless told otherwise, and fails if no 'nodes'
# object exists
nodes  &amp;lt;- newnode(name=&quot;NAME&quot;,inputs=&quot;INPUT&quot;,outputs=&quot;OUTPUT&quot;, newgraph = T)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/newnode1.png&quot; alt=&quot;images/newnode1.png&quot; /&gt;&lt;/p&gt;

&lt;h4&gt;Code:adding nodes&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# now we can add nodes, and we can pass multiple inputs or outputs
nodes  &amp;lt;- newnode(name=&quot;OUTPUT&quot;,inputs=c(&quot;NAME&quot;,&quot;ANOTHER THING&quot;))
# outputs are optional
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/newnode2.png&quot; alt=&quot;images/newnode2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It can be used in two or three ways.&lt;/p&gt;

&lt;h2&gt;Example one, the composite view:&lt;/h2&gt;

&lt;p&gt;So if there is a Balzerian filelist table available, convert it to a spreadsheet.  This is als similar to a labbook from Chemistry but follows a very rigid structure: NAME,        INPUTS,           OUTPUTS,         DESCRIPTION.  The first method I'll show will take one of these tables and map out the steps in the workflow.&lt;/p&gt;

&lt;h4&gt;Code: Composite Worflow Files List&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#    so if there is a Balzerian filelist table available,
# either make a spreadsheet with names, inputs and outputs 
# fileslist &amp;lt;- read.csv(&quot;exampleFilesList.csv&quot;, stringsAsFactors = F)
# or 
filesList &amp;lt;- read.csv(textConnection(
'NAME,        INPUTS,           OUTPUTS,         DESCRIPTION
FileA,        TableXYZ,         Input1,          Transformed variable
FileB,        TableABC,         Input2,          Collapsed dimensions
analysisFile, &quot;Input1,Input2&quot;,  analysisResults, Merged inputs and analysed
'), stringsAsFactors = F, strip.white = T)
filesList

for(i in 1:nrow(filesList))
{
  nodes &amp;lt;- newnode(name = filesList[i,&quot;NAME&quot;],
                   inputs = strsplit(filesList$INPUTS, &quot;,&quot;)[[i]],
                   outputs = strsplit(filesList$OUTPUTS, &quot;,&quot;)[[i]],
                   newgraph = (i == 1)
  )
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;shows this result&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/fileRelationships.png&quot; alt=&quot;fileRelationships.png&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Example two, tracking the steps while analysing data:&lt;/h2&gt;

&lt;p&gt;Structure a script into sections and document each section before evaluating the code to execute the step.  This works well with orgmode/ESS, Sweave or knitr style workflows.
For example:&lt;/p&gt;

&lt;h4&gt;Code: Ad Hoc Files Lists Flowcharts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#### step one ####
nodes &amp;lt;- newnode(name=&quot;FileA&quot;, inputs=&quot;TableXYZ&quot;, outputs=&quot;Input1&quot;,
                 newgraph =T) # this is required to tell newnode to
                              # start a new graph, rather than add to
                              # the nodes
FileA  &amp;lt;- read.table(&quot;TableXYZ.txt&quot;)
Input1 &amp;lt;- log(FileA$columnZ)

#### step two ####
nodes &amp;lt;- newnode(name=&quot;FileB&quot;, inputs=&quot;TableABC&quot;, outputs=&quot;Input2&quot;)
FileB  &amp;lt;- read.table(&quot;TableABC.txt&quot;)
Input2 &amp;lt;- ddply(FileB, &quot;id&quot;, summarise,
                duration = max(year) - min(year),
                nteams = length(unique(team)))

#### step three ####
nodes &amp;lt;- newnode(name=&quot;analysisFile&quot;, inputs=c(&quot;Input1&quot;,&quot;Input2&quot;),
                 outputs=&quot;analysisResults&quot;)
analysisFile  &amp;lt;- merge(Input1, Input2, by=&quot;id&quot;)
analysisResults  &amp;lt;- lm(y ~ duration + nteams, data = analysisFile)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Example three: visualising relationships&lt;/h2&gt;

&lt;p&gt;It is not aimed at visualising the linked structure of a tree or semi-lattice but can be used in such a way but changing the nodename and inputs concept to parent/child relationships.&lt;/p&gt;

&lt;p&gt;As an example I'll describe how a list of database tables might be displayed as a tree. I am a great fan of Josh Reich due to his &lt;a href=&quot;http://stackoverflow.com/a/1434424&quot;&gt;LCFD workflow&lt;/a&gt;, and I also like his work on the &lt;a href=&quot;https://www.simple.com/&quot;&gt;Simple Bank&lt;/a&gt; so when I stumbled on this &lt;a href=&quot;http://blog.i2pi.com/post/52812976752/joshs-postgresql-database-conventions&quot;&gt;blog post&lt;/a&gt; in which he says:&lt;/p&gt;

&lt;p&gt;&quot;Show me your flowchart and conceal your tables, and I shall continue to be mystified. Show me your tables, and I won’t usually need your flowchart; it’ll be obvious.&quot;&lt;/p&gt;

&lt;p&gt;I was switched on and I started thinking about how the graphVis tool could be used to describe a list of tables and views from a database.&lt;/p&gt;

&lt;p&gt;Say that two groups studied the same file TableXYZ with different inputs.  One of these groups wrote a seminal paper in the field, while their rivals wrote an inferior paper with a different result.  Imagine now a subsequent group who gathered the data from the previous work into the following database tables and conducted a replication study, with a new sensitivity analysis to explain why the original two papers produced different results.&lt;/p&gt;

&lt;p&gt;Let's assume this database has all the data from all the groups in it and we want to get a pictorial view so we can disentangle which files belong to which study.  First get the following list of tables as INPUTS, grouping them by 'NAME' will give the tree structure and showing their results as OUTPUTS allows the subsequent replication study to use them as inputs and assume the position at the bottom of the flowchart.&lt;/p&gt;

&lt;h4&gt;Code: database tables and different studies&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;filesList &amp;lt;- read.csv(textConnection(
'NAME                 ,             INPUTS         , OUTPUTS
The Seminal Study     ,              FileA         , 
The Seminal Study     ,              FileB         , 
The Seminal Study     ,       analysisFile         , 
The Seminal Study     ,           TableXYZ         , 
The Seminal Study     ,           TableABC         , 
The Seminal Study     ,      Input1,Input2         ,
The Seminal Study     ,             Input1         , 
The Seminal Study     ,             Input2         , 
The Seminal Study     ,      The Seminal Study     , analysisResults 
The Inferior Rivals   ,                FileC       , 
The Inferior Rivals   ,        analysisFileX       , 
The Inferior Rivals   ,             TableXYZ       , 
The Inferior Rivals   ,               InputX       , 
The Inferior Rivals   ,    The Inferior Rivals     , analysisResultsX       
The Replication Study ,    &quot;Input1,Input2,TableXYZ&quot;,  analysisResultsR     
The Replication Study ,    &quot;Input1,InputX,TableXYZ&quot;,  sensitivityResult 
'), stringsAsFactors = F, strip.white = T)

for(i in 1:nrow(filesList))
{
  nodes &amp;lt;- newnode(name = filesList[i,&quot;NAME&quot;],
                   inputs = strsplit(filesList$INPUTS, &quot;,&quot;)[[i]],
                   outputs = strsplit(filesList$OUTPUTS, &quot;,&quot;)[[i]],
                   newgraph = (i == 1)
  )
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;the result&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/filesRelationships2.png&quot; alt=&quot;filesRelationships2.png&quot; /&gt;&lt;/p&gt;
</description>
				<published>Wed Jul 31 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/07/worflow-flowcharts/</link>
			</item>
		
			<item>
				<title>animated-maps</title>
				<description>&lt;h1&gt;Animated maps to allow exploration of alternate levels of 'jitter'&lt;/h1&gt;

&lt;p&gt;In a &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/22672028&quot;&gt;previous project&lt;/a&gt; we published a map of point locations that had been 'jittered', ie adding random noise to the latitude and longitude.  We did this by testing out a few maps and deciding on one that we thought protected privacy adequately whilst not destroying the spatial pattern we wished to display (evocatively).&lt;/p&gt;

&lt;p&gt;I always wondered about a way to interactively do this and I think the animation package might do the trick, with the ability to step thru levels of jittering with the pause, fwd and back buttons.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/jitter/index.html&quot;&gt;Clink here for the same data shown in a new animation&lt;/a&gt;.&lt;/p&gt;

&lt;h1&gt;Reference&lt;/h1&gt;

&lt;p&gt;Vally, H., Peel, M., Dowse, G. K., Cameron, S., Codde, J. P., Hanigan, I., &amp;amp; Lindsay, M. D. a. (2012). Geographic Information Systems used to describe the link between the risk of Ross River virus infection and proximity to the Leschenault estuary, WA. Australian and New Zealand Journal of Public Health, 36(3), 229–235. doi:10.1111/j.1753-6405.2012.00869.x&lt;/p&gt;
</description>
				<published>Tue Jul 30 00:00:00 +1000 2013</published>
				<link>http://schamberlain.github.com/2013/07/animated-maps/</link>
			</item>
		
	</channel>
</rss>