<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>Recology</title>
		<description>An exploration of using R for ecology, evolution, and open science.</description>
		<link>http://schamberlain.github.com</link>
		
			<item>
				<title>a-sharp-looking-orgmode-latex-export-header</title>
				<description>&lt;ul&gt;
&lt;li&gt;I got this header for a nice looking report from Bull, G. (2011). Example Sweave Document. SharpStatistics.co.uk.&lt;/li&gt;
&lt;li&gt;This has a bunch of useful parameters, but I just really like the header and footer on pages 2 onward&lt;/li&gt;
&lt;li&gt;The original was a Sweave file.  I really like Sweave but orgmode allows other languages as well as R to be inter-woven into the script&lt;/li&gt;
&lt;li&gt;An alternative to Sweave is knitr and is still on my todo list, but this works well at the moment&lt;/li&gt;
&lt;li&gt;I also like how you can quickly change this to a Beamer presentation style.&lt;/li&gt;
&lt;li&gt;Once this is in your file use C-c C-e d to export and compile the PDF&lt;/li&gt;
&lt;li&gt;This example is available at &lt;a href=&quot;/pdfs/SharpReportTemplate.pdf&quot;&gt;this link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Emacs orgmode Code: Put this into your .org file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;#+TITLE: Sharp Report Template
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LaTeX_HEADER: \usepackage{tabulary}
#+LaTeX_HEADER: \usepackage{longtable}
#+latex_header: \usepackage{rotating}
#+LaTeX_HEADER: \usepackage{graphicx} 
#+LaTeX_HEADER: \usepackage{amssymb,amsmath}
#+LaTeX_HEADER: \usepackage{fancyhdr} %For headers and footers
#+LaTeX_HEADER: \pagestyle{fancy} %For headers and footers
#+LaTeX_HEADER: \usepackage{lastpage} %For getting page x of y
#+LaTeX_HEADER: \usepackage{float} %Allows the figures to be positioned and formatted nicely
#+LaTeX_HEADER: \floatstyle{boxed} %using this
#+LaTeX_HEADER: \restylefloat{figure} %and this command
#+LaTeX_HEADER: \usepackage{url} %Formatting of yrls
#+LaTeX_HEADER: \usepackage{verbatim} 
#+LaTeX_HEADER: \lhead{ivanhanigan.github.com}
#+LaTeX_HEADER: \chead{}
#+LaTeX_HEADER: \rhead{\today}
#+LaTeX_HEADER: \lfoot{Draft}
#+LaTeX_HEADER: \cfoot{}
#+LaTeX_HEADER: \rfoot{\thepage\ of \pageref{LastPage}}
#+LATEX: \tableofcontents

* Introduction
This is a sharp looking report template I got from \cite{Bull2011}.
\clearpage

* Section 1
The pages after the first page have a nice looking header, footer and page number.
\clearpage

* References
\bibliographystyle{apalike}
\bibliography{/home/ivan_hanigan/references/library}
&lt;/code&gt;&lt;/pre&gt;
</description>
				<published>Tue Nov 26 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/a-sharp-looking-orgmode-latex-export-header/</link>
			</item>
		
			<item>
				<title>Setting Up A Workflow Script With Code Chunks</title>
				<description>&lt;p&gt;This post describes some ideas and techniques I use to set up a &quot;workflow script&quot;.  I use this term to refer to the structured combination of code, data and narrative that make an executable Reproducible Research Report (RRR).&lt;/p&gt;

&lt;p&gt;A lot of these ideas are inpsired by  a great paper by Kieran Healy called  &quot;Choosing Your Workflow Applications&quot; available at &lt;a href=&quot;https://github.com/kjhealy/workflow-paper&quot;&gt;https://github.com/kjhealy/workflow-paper&lt;/a&gt; to accompany &lt;a href=&quot;http://kieranhealyo.org/resources/emacs-starter-kit.html&quot;&gt;his Emacs Starter Kit&lt;/a&gt;. My shortened version of his main points are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 use a good code editor&lt;/li&gt;
&lt;li&gt;2 analyse data with scripts&lt;/li&gt;
&lt;li&gt;3 store your work simply and document it properly&lt;/li&gt;
&lt;li&gt;4 use a version control system&lt;/li&gt;
&lt;li&gt;5 Automate back ups&lt;/li&gt;
&lt;li&gt;6 Avoid distracting gadgets&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Here's my current approach in each of these categories&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;1 use Emacs with Orgmode (and kjhealy's drop-in set of useful defaults)&lt;/li&gt;
&lt;li&gt;2 Scripts that utilise the literate programming technique of mixing Code Chunks in with descriptive prose&lt;/li&gt;
&lt;li&gt;3 John Myles White's ProjectTemplate R Package and Josh Riech's LCFD paradigm&lt;/li&gt;
&lt;li&gt;4 git and GitHub for version control&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;5 Automated Backups and 6 Avoiding Gadgets are still somethings I find challenging&lt;/p&gt;

&lt;h4&gt;1 Use a good code editor&lt;/h4&gt;

&lt;p&gt;I like using Emacs with Orgmode.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I have previously tried a variety of code editors from Tinn-r, NppToR, Rstudio and Eclipse.&lt;/li&gt;
&lt;li&gt;Emacs with Orgmode suits me the most because it has a great number of features especially the linkage with LaTeX or HTML export&lt;/li&gt;
&lt;li&gt;A key reference to look at for reasons why Emacs is so good for scientific work is Eric Schulte et al &lt;a href=&quot;www.jstatsoft.org/v46/i03%E2%80%8E&quot;&gt;&quot;A Multi-Language Computing Environment for Literate Programming&quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Here is a &lt;a href=&quot;http://doc.norang.ca/org-mode.html&quot;&gt;link to a great orgmode description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(this guy spends a lot of time on tweaking his set up)&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;2 Analyse data with Scripts (stitch together code chunks)&lt;/h4&gt;

&lt;p&gt;I use Scripts but prefer to think of them as stitched together Code Chunks with prose into Compendia.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Compendia are documents that weave together Code and Prose into an executable report&lt;/li&gt;
&lt;li&gt;The underlying philosophy is called Reproducible Research Reports&lt;/li&gt;
&lt;li&gt;A very useful tool is a keyboard shortcut to quickly create a chunk for code&lt;/li&gt;
&lt;li&gt;so you can be writing parts of the report like this: &quot;Blah Blah Blah as shown in Figure X and Table Y&quot;&lt;/li&gt;
&lt;li&gt;then just hit the correct keys and WHAMM-O there is a new chunk ready for the code that creates Figure X and Table Y to be written.&lt;/li&gt;
&lt;li&gt;Here is how I use Emacs to achieve this (the other editors I mentioned above also have the abiltiy to do this too).  The IPython Notebook does this stuff too but calls chunks &quot;cells&quot; for some reason.&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Emacs Code: Put this into the ~/.emacs.d/init.el file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;(define-skeleton chunk-skeleton
  &quot;Info for a code chunk.&quot;
  &quot;Title: &quot;
  &quot;*** &quot; str &quot;-code\n&quot;
  &quot;#+name:&quot; str &quot;\n&quot;
  &quot;#+begin_src R :session *R* :tangle src/&quot; str &quot;.r :exports reports :eval no\n&quot;
  &quot;#### name:&quot; str &quot; ####\n&quot;
  &quot;\n&quot;
  &quot;#+end_src\n&quot;
)
(global-set-key [?\C-x ?\C-\\] 'chunk-skeleton)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Using the Emacs Shortcut&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;now whenever you type Control-x control-\ a new code chunk will appear&lt;/li&gt;
&lt;li&gt;you'll be typing &quot;blah blah blah&quot; and think I need a figure or table, just hit it.&lt;/li&gt;
&lt;li&gt;move into the empty section and add some code&lt;/li&gt;
&lt;li&gt;you can hit C-c ' to enter a org-babel code execution session that will be able to send these line by line to an R session&lt;/li&gt;
&lt;li&gt;or within the main org buffer if your eval flag is set to yes then you can run the entire chunk (and return tabular output to the doc) using C-c C-c&lt;/li&gt;
&lt;li&gt;To export the code chunks and create the modular code scripts without the narrative prose use C-c C-v t&lt;/li&gt;
&lt;li&gt;this is called &quot;tangling&quot; and the chunks will be written out to the file specified in the chunk header &quot;:tangle&quot; flag&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Compiling the resulting Compendium&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Emacs uses LaTeX or HTML to produce the Report&lt;/li&gt;
&lt;li&gt;I find both of these outputs very pleasing&lt;/li&gt;
&lt;li&gt;to compile to TEX use C-c C-e d&lt;/li&gt;
&lt;li&gt;for HTML use C-c C-e h (FOR CODE HIGHLIGHTING INSTALL htmlize.el)&lt;/li&gt;
&lt;li&gt;these commands will also evaluate all the chunks where &quot;:eval&quot; = yes to load the data and calculate the results fresh.&lt;/li&gt;
&lt;li&gt;AWESOME!&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;3 Store your work simply and document it properly&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I use the &lt;a href=&quot;http://www.johnmyleswhite.com/notebook/2010/08/26/projecttemplate/&quot;&gt;ProjectTemplate R package&lt;/a&gt; to organise my code sections into modules&lt;/li&gt;
&lt;li&gt;These modules are organised into the Reichian LCFD paradigm described first &lt;a href=&quot;http://stackoverflow.com/a/1434424&quot;&gt;on StackOverflow here&lt;/a&gt;, and encoded into &lt;a href=&quot;http://cran.r-project.org/web/packages/makeProject/makeProject.pdf&quot;&gt;the makeProject R package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;documentation is within the main orgmode script&lt;/li&gt;
&lt;li&gt;data documentation is a whole other universe that I will deal with in a separate post&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;4 use a version control system using git and github&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# once you have the project via R
R
require(ProjectTemplate)
create.project(&quot;AwesomeProject&quot;, minimal = T)
q()
# use the shell to start a git repo
cd AwesomeProject
git init
# and commit the TODO
git add TODO
git commit -m &quot;first commit&quot;
# tada!
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Emacs can now be used to manage the git repo using the C-x g command&lt;/li&gt;
&lt;li&gt;Rstudio has a really nice GUI for doing this inside it;s Project management interface too.&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Using Github or another Git Server&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;You can easily set up a Github repo for this now but it will be public&lt;/li&gt;
&lt;li&gt;Alternatative is to set up your own private Git server.  I followed &lt;a href=&quot;http://blog.goosoftware.co.uk/2012/02/07/quick-git-server/&quot;&gt;these instructions to Running a Simple Git Server Using SSH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Either way once you have set up your remote git repo you need to set the remote tracking&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Git Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;cd /path/to/local/git/repo
git remote add origin git@github-or-other-server:myname/myproject.git
git push origin master
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5 Automate back ups AND 6 Avoid distracting gadgets&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;OMG backups stress me out&lt;/li&gt;
&lt;li&gt;ideally I would follow &lt;a href=&quot;http://www.jwz.org/blog/2007/09/psa-backups/&quot;&gt;this advice because &quot;when it comes to losing your data the universe tends toward maximum irony. Don't push it.&quot;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;But I don;t fully comply&lt;/li&gt;
&lt;li&gt;Instead I generally use Dropbox for  basic project management admin stuff&lt;/li&gt;
&lt;li&gt;I use github for code projects I am happy to share, I also pay for 10 private repos&lt;/li&gt;
&lt;li&gt;I Set up a git server at my workplace for extra projects but this is on a test server that is not backed up, and I am not really happy about this&lt;/li&gt;
&lt;li&gt;In terms of Distracting Gadgets, I think that with the current tempo of new innovations related to new software tools for this type of work I should keep trying new things but I have pretty much settled into a comfortable zone with the gadgets I described here.&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Conclusions&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;This is how I've worked for a couple of years&lt;/li&gt;
&lt;li&gt;I find it very enjoyable, mostly productive but prone to the distractions of &quot;distractions by gadgets&quot;&lt;/li&gt;
&lt;li&gt;The main thing I want to point out is the usage of Code Chunks in RRR scripts.&lt;/li&gt;
&lt;li&gt;These things are awesome.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Mon Nov 25 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/setting-up-a-workflow-with-code-chunks/</link>
			</item>
		
			<item>
				<title>sync-endnote-and-mendeley-references-using-r-xml</title>
				<description>&lt;h4&gt;Background&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I use Mendeley (despite them being bought out by Elsevier, who used to sell guns)&lt;/li&gt;
&lt;li&gt;My Colleagues use EndNote&lt;/li&gt;
&lt;li&gt;Need to sync, they find Endnote better for their workflow&lt;/li&gt;
&lt;li&gt;I tried to export my Mendeley as XML and import to Endnote, but found many duplicates that took time to rectify&lt;/li&gt;
&lt;li&gt;(and the risk is there that the RefNo they used in the Doc will be the duplicate that I removed)&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Aims&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;test if R and the XML package can help find refs in Endnote that aren't in Mendeley&lt;/li&gt;
&lt;li&gt;If so can I write those into an Mendeley import for seamless integrations&lt;/li&gt;
&lt;li&gt;and what about going from Mendeley to Endnote?&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;The R XML package seems an obvious place to start&lt;/li&gt;
&lt;li&gt;before writing a function, just step thru the process&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Step 1: export XML from Mendeley and Endnote&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;In Mendeley Just select the refs in the list and then from the file menu&lt;/li&gt;
&lt;li&gt;In Endnote it is also under File menu&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Step 2: R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# func
# might need sudo apt-get install r-cran-xml?
require(XML)

# load
dir()
[1] &quot;EndnoteCollection.xml&quot;
    &quot;MendeleyCollection.Data&quot;
[3] &quot;MendeleyCollection.xml&quot; 

d1 &amp;lt;- xmlTreeParse(&quot;EndnoteCollection.xml&quot;, useInternal=T)

# clean
str(d1)
# ooooh xml schmexemhel voodoo?

# do
top &amp;lt;- xmlRoot(d1)
str(top)
names(top)
# top [[1]] # prints the whole thing
top [[1]][[1]]
top [[1]][[2]]
# prints a record (1 or 2)

# just messing around
length(top[[1]])
top [[1]][[120]]
names(top [[1]][[120]])
names(top [[1]][[120]][[&quot;contributors&quot;]])
names(top [[1]][[120]][[&quot;contributors&quot;]][[&quot;authors&quot;]])
top [[1]][[120]][[&quot;contributors&quot;]][[&quot;authors&quot;]][[2]]

i &amp;lt;- 110
top [[1]][[i]]
as.matrix(names(top [[1]][[i]]))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;OK so XML as a list.&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I think if I do a merge of two author-date-title dataframes I can easily find the diffs&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;TRY a square wheel&lt;/h4&gt;

&lt;h4&gt;R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;endnote_mendeley_df &amp;lt;- function(input_xml,
                                nrow_to_try = 1000){
  d1 &amp;lt;- xmlTreeParse(input_xml, useInternal=T)
  top &amp;lt;- xmlRoot(d1)

  output &amp;lt;- matrix(ncol = 4, nrow = 0)
  for(i in 1:nrow_to_try)
  {
  # i = 1000
    if(is.na(xmlValue(top [[1]][[i]]))) break
    if(
      !is.na(xmlValue(top [[1]][[i]][[&quot;contributors&quot;]][[&quot;authors&quot;]][[2]]))
      )
    {
      author &amp;lt;- paste(xmlValue(top [[1]][[i]][[&quot;contributors&quot;]][[&quot;authors&quot;]][[1]]), &quot;et al&quot;, &quot; &quot;)
    } else {
      author &amp;lt;- xmlValue(top [[1]][[i]][[&quot;contributors&quot;]][[&quot;authors&quot;]][[1]])
    }
    year &amp;lt;- xmlValue(top [[1]][[i]][[&quot;dates&quot;]][[&quot;year&quot;]])
    title &amp;lt;- xmlValue(top [[1]][[i]][[&quot;titles&quot;]][[1]])
    endnoteref &amp;lt;- xmlValue(top [[1]][[i]][[&quot;rec-number&quot;]])
    output &amp;lt;- rbind(output, c(author, year, title, endnoteref))

  }
  output &amp;lt;- as.data.frame(output)
  return(output)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Test:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;output &amp;lt;- endnote_mendeley_df(
  input_xml = &quot;EndnoteCollection.xml&quot;
  ,
  nrow_to_try = 10
  )

nrow(output)
write.csv(output, &quot;EndnoteCollection.csv&quot;, row.names = F)
output  &amp;lt;- read.csv(&quot;EndnoteCollection.csv&quot;, stringsAsFactors = F)
str(output)
output[,1:2]
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Do-read:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;endnote &amp;lt;- endnote_mendeley_df(
  input_xml = &quot;EndnoteCollection.xml&quot;
  )
nrow(endnote)
mendeley &amp;lt;- endnote_mendeley_df(
  input_xml = &quot;MendeleyCollection.xml&quot;
  )
nrow(mendeley)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Do-concatenate and lowercase&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;# TODO this is a really terrible way to do this.
# FIXME find out how to compare the two better
require(stringr)
mendeley2 &amp;lt;- str_c(mendeley$V1, mendeley$V2, mendeley$V3)
mendeley2 &amp;lt;- gsub(&quot; &quot;, &quot;&quot;, mendeley2)
mendeley2 &amp;lt;- gsub(&quot;,&quot;, &quot;&quot;, mendeley2)
mendeley2 &amp;lt;- tolower(mendeley2)
mendeley2[1:5]
mendeley$mendeley2 &amp;lt;- mendeley2

# now do this again from endnote
endnote2 &amp;lt;- str_c(endnote$V1, endnote$V2, endnote$V3)
endnote2 &amp;lt;- gsub(&quot; &quot;, &quot;&quot;, endnote2)
endnote2 &amp;lt;- gsub(&quot;,&quot;, &quot;&quot;, endnote2)
endnote2 &amp;lt;- tolower(endnote2)
endnote2[1:5]
endnote$endnote2 &amp;lt;- endnote2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Do-merge:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;endnote_not_in_mendeley &amp;lt;- merge(endnote,
                                 mendeley,
                                 by.x = &quot;endnote2&quot;,
                                 by.y = &quot;mendeley2&quot;,
                                 all.x = T)
str(endnote_not_in_mendeley)
nrow(endnote_not_in_mendeley)
head(endnote_not_in_mendeley)
endnote_not_in_mendeley &amp;lt;- endnote_not_in_mendeley[
                                                   is.na(endnote_not_in_mendeley$V1.y),
                                                   ]
nrow(endnote_not_in_mendeley)
# 66 refs in endnote are not in mendeley
write.csv(endnote_not_in_mendeley,
      &quot;endnote_not_in_mendeley.csv&quot;, row.names = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Open this as spreadsheet and cross check&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;make a new column for comments&lt;/li&gt;
&lt;li&gt;check off which ones were in AllDocuments and not in the Mendeley group&lt;/li&gt;
&lt;li&gt;this diff was because of when I imported the Endnote XML but had not assigned these to the mendeley group&lt;/li&gt;
&lt;li&gt;once have cleaned up the mendeley group export again and then check which are in mendeley but not in endnote&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;First here is a note&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;about a way to speed up the checks, excluding false positives using fuzzy matching&lt;/li&gt;
&lt;li&gt;my method relies on the author, date and title to be written the same in both ie initials then surname or visa verca&lt;/li&gt;
&lt;li&gt;But this is not always true&lt;/li&gt;
&lt;li&gt;I previously used levenshtein string matching to identify strings that are close but not identical&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.r-project.org/rwiki/doku.php?id=tips:data-strings:levenshtein&quot;&gt;Try this link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://rwiki.sciviews.org/doku.php?id=tips:data-strings:levenshtein&quot;&gt;OR this link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TODO I will share this code as a GitHub Gist later!&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;R Code: possibility to speed up Checks&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;tmp1 &amp;lt;- mendeley[grep(&quot;Walker&quot;, mendeley$V1),&quot;mendeley2&quot;]
tmp2 &amp;lt;- endnote[grep(&quot;Walker&quot;, endnote$V1),&quot;endnote2&quot;]

# these differ slightly
# B. Walker et al vs Walker, Brian et al
source(&quot;~/Dropbox/tools/levenshtein.r&quot;)
levenshtein(
    tmp1
    ,
    tmp2
    )
# gives 92percent match
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Code: Find mendeley refs without endnote&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;  endnote &amp;lt;- endnote_mendeley_df(
    input_xml = &quot;EndnoteCollection.xml&quot;
    )
  nrow(endnote)
  mendeley &amp;lt;- endnote_mendeley_df(
    input_xml = &quot;MendeleyCollection2.xml&quot;
    )
  nrow(mendeley)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Code: Do-concatenate and lowercase&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;require(stringr)
mendeley2 &amp;lt;- str_c(mendeley$V1, mendeley$V2, mendeley$V3)
mendeley2 &amp;lt;- gsub(&quot; &quot;, &quot;&quot;, mendeley2)
mendeley2 &amp;lt;- gsub(&quot;,&quot;, &quot;&quot;, mendeley2)
mendeley2 &amp;lt;- tolower(mendeley2)
mendeley2[1:5]
mendeley$mendeley2 &amp;lt;- mendeley2

# now do this again from endnote
endnote2 &amp;lt;- str_c(endnote$V1, endnote$V2, endnote$V3)
endnote2 &amp;lt;- gsub(&quot; &quot;, &quot;&quot;, endnote2)
endnote2 &amp;lt;- gsub(&quot;,&quot;, &quot;&quot;, endnote2)
endnote2 &amp;lt;- tolower(endnote2)
endnote2[1:5]
endnote$endnote2 &amp;lt;- endnote2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Do-merge:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;mendeley_not_in_endnote &amp;lt;- merge(mendeley,
                                 endnote,
                                 by.y = &quot;endnote2&quot;,
                                 by.x = &quot;mendeley2&quot;,
                                 all.x = T)
str(mendeley_not_in_endnote)
nrow(mendeley_not_in_endnote)
head(mendeley_not_in_endnote)
mendeley_not_in_endnote &amp;lt;- mendeley_not_in_endnote[
                                                      is.na(mendeley_not_in_endnote$V1.y),
                                                      ]
nrow(mendeley_not_in_endnote)
# 92 refs in endnote are not in mendeley
write.csv(mendeley_not_in_endnote,
      &quot;mendeley_not_in_endnote.csv&quot;, row.names = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Not all these 92 will be true&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;so let;s try the string matching&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;R Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;source(&quot;~/Dropbox/tools/levenshtein.r&quot;)
pcnt_threshold &amp;lt;- 0.6
out_list &amp;lt;- matrix(ncol = 3, nrow = 0)
#out_list &amp;lt;- read.csv(&quot;mendeley_not_in_endnote_fz_match.csv&quot;, stringsAsFactors = F)
for(i in 36:nrow(mendeley_not_in_endnote))
    {
        print(i)
#        i = 2
tmp1 &amp;lt;- mendeley_not_in_endnote[i,1]
    for(j in 1:nrow(endnote))
        {
    #        j = 2
    if(exists(&quot;out&quot;)) rm(out)
    tmp2 &amp;lt;- endnote$endnote2[j]
    pcnt &amp;lt;- levenshtein(
            tmp1
            ,
            tmp2
            )
    #pcnt
    if(pcnt &amp;gt;= pcnt_threshold) out &amp;lt;- tmp2
    if(exists(&quot;out&quot;))
        out_list &amp;lt;- rbind(out_list, c(tmp1, tmp2, pcnt))
    if(exists(&quot;out&quot;)) break
        }

    }
out_list
write.csv(out_list, &quot;mendeley_not_in_endnote_fz_match.csv&quot;, row.names = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;R Code: Do-concatenate and lowercase&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;require(stringr)
out_list &amp;lt;- read.csv(&quot;mendeley_not_in_endnote_fz_match.csv&quot;, stringsAsFactors = F)
mendeley2 &amp;lt;- read.csv(&quot;mendeley_not_in_endnote.csv&quot;, stringsAsFactors=F)
mendeley2[1,]
out_list[1,]
mendeley2 &amp;lt;- merge(mendeley_not_in_endnote, out_list,
                   by.x = &quot;mendeley2&quot;,
                   by.y = &quot;V1&quot;, all.x = T)
mendeley2[2,]
mendeley2 &amp;lt;- mendeley2[is.na(mendeley2$V3),]
nrow(mendeley2)
# 48 records
write.csv(mendeley2, &quot;mendeley_not_in_endnote_best_estimate.csv&quot;, row.names=F)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Results&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I found that XML package in R can work with the Endnote and Mendeley export Files&lt;/li&gt;
&lt;li&gt;I think I made a lot of bad decisions about the way I went about  doing this!&lt;/li&gt;
&lt;li&gt;It seemed quite difficult to get the XML stuff to make sense to me&lt;/li&gt;
&lt;li&gt;I;ve heard that python has better libraries for working with XML&lt;/li&gt;
&lt;li&gt;the levenshtein string matching code proved useful again.  I should get out of the habit of looping and start using lapply etc to speed this up.&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Conclusions&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;This was an interesting if frustrating experiment&lt;/li&gt;
&lt;li&gt;The minor issues with importing from mendeley/endnote and deduplicating using their own tools was probably not worth writing all this half-baked R code.&lt;/li&gt;
&lt;li&gt;But I did learn more about working with XML in R (and realised this is probably not one of R's Strengths -- or mine for that matter!)&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Wed Nov 20 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/sync-endnote-and-mendeley-using-r-xml/</link>
			</item>
		
			<item>
				<title>git-can-be-simple-or-very-complicated</title>
				<description>&lt;ul&gt;
&lt;li&gt;Git is a Distributed Version Control System.&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;centerforopenscience.org&quot;&gt;centerforopenscience.org&lt;/a&gt; has developed the Open Science Framework  which is they say &quot;a simplified front end to the powerful and popular version control system Git&quot;.&lt;/li&gt;
&lt;li&gt;I use Github a lot for extending the local features into an online space&lt;/li&gt;
&lt;li&gt;So I finally got around to poking the open science framework with the &lt;a href=&quot;https://openscienceframework.org/project/pyts3/&quot;&gt;Hutchinson Drought Index project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;It turns out to be too simplified, and not have very many of the feature I love about Git and GitHub :-(&lt;/li&gt;
&lt;li&gt;For eg it is not really distributed in that you don't get to sync your local repo with the onlin version&lt;/li&gt;
&lt;li&gt;you upload a script or dataset, then you continue editing locally until you want to commit and then you have to upload again, one file at a time with the GUI rather than &quot;git add .&quot; and &quot;git push&quot;.&lt;/li&gt;
&lt;li&gt;I recommend having a look, it might work for you, but if you want more power checkout Yihui's suggestions for using github &lt;a href=&quot;http://yihui.name/en/2011/12/how-to-become-an-efficient-and-collaborative-r-programmer/&quot;&gt;http://yihui.name/en/2011/12/how-to-become-an-efficient-and-collaborative-r-programmer/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;and &lt;a href=&quot;http://yihui.name/en/2013/06/fix-typo-in-documentation/&quot;&gt;http://yihui.name/en/2013/06/fix-typo-in-documentation/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;In general I don't think simple front-end's should be a barrier to accessing a sophisticated back-end!&lt;/h4&gt;
</description>
				<published>Tue Nov 19 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/git-can-be-simple-or-very-complicated/</link>
			</item>
		
			<item>
				<title>nectar cloud pumilio build got bogged down</title>
				<description>&lt;p&gt;I've been trying to build pumilio bioacoustics server on a Aust Nectar Research Cloud VM, but hit various roadblocks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;built with NeCTAR Ubuntu 12.04.2 (Precise)&lt;/li&gt;
&lt;li&gt;these issues (especially the apt-get install r-cran-mysql etc ) might not occure with later Ubuntu?&lt;/li&gt;
&lt;li&gt;test NeCTAR Ubuntu 12.10 (Quantal) or&lt;/li&gt;
&lt;li&gt;NeCTAR Ubuntu 13.04 (Raring) ??&lt;/li&gt;
&lt;li&gt;TODO FIX issues with python audio lab&lt;/li&gt;
&lt;li&gt;TODO swapfile&lt;/li&gt;
&lt;li&gt;TODO Mount the larger storage&lt;/li&gt;
&lt;li&gt;TODO add swapfile&lt;/li&gt;
&lt;li&gt;TODO fix R install etc&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The Github code (in the gh-pages branch) and published as &lt;a href=&quot;http://ivanhanigan.github.io/pumilio-bushfm/&quot;&gt;a report at this link&lt;/a&gt;.  The Source Code is available to Clone or Fork at &lt;a href=&quot;https://github.com/ivanhanigan/pumilio-bushfm&quot;&gt;This Github Repo&lt;/a&gt; and is at a stage that most of the installation and configuration is documented to a point where a test sound file has successfully been uploaded.&lt;/p&gt;

&lt;h4&gt;HELP WANTED&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Any researcher at an Australia university could follow the instructions on their own Nectar Cloud VM.&lt;/li&gt;
&lt;li&gt;If anybody out there is interested in bioacoustics, R, Linux or web data archives please help&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Background to pumilio, bushfm and this project&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/birdcombined.png&quot; alt=&quot;birdcombined.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;a href=&quot;pumilio%20project&quot;&gt;http://pumilio.sourceforge.net/&lt;/a&gt; is by Luis J. Villanueva-Rivera and Bryan C. Pijanowski. (2012. Pumilio: A Web-Based Management System for Ecological Recordings. Bulletin of the Ecological Society of America 93: 71-81. doi: 10.1890/0012-9623-93.1.71)&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;Bush-fm%20project&quot;&gt;http://www.bush.fm/&lt;/a&gt; aims to provide the research community with a portal to national scale acoustic sensor data repositories, and a suite of tools to perform analysis and reporting on these data.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;(Images from http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000M4)&lt;/p&gt;
</description>
				<published>Mon Nov 18 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/nectar-cloud-pumilio-build-got-bogged-down/</link>
			</item>
		
			<item>
				<title>really-useful-r-upcase-string</title>
				<description>&lt;p&gt;Here is a really useful R snippet from  &lt;a href=&quot;http://stackoverflow.com/a/6364905&quot;&gt;http://stackoverflow.com/a/6364905&lt;/a&gt; with a minor modification to allow differnt splits&lt;/p&gt;

&lt;h4&gt;Code:r-upcase-string&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;x &amp;lt;- c(&quot;The&quot;, &quot;quick&quot;, &quot;Brown&quot;, &quot;fox/lazy dog&quot;)

simpleCap &amp;lt;- function(x, tosplit = &quot; &quot;) {
  s &amp;lt;- strsplit(x, tosplit)[[1]]
  paste(toupper(substring(s, 1,1)), substring(s, 2),
      sep=&quot;&quot;, collapse=tosplit)
}
sapply(x, simpleCap)
sapply(x, simpleCap, tosplit = &quot;/&quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<published>Sun Nov 17 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/really-useful-r-upcase-string/</link>
			</item>
		
			<item>
				<title>pumilio-bushfm-test-dev-prod</title>
				<description>&lt;h1&gt;Testing the pumilio-bushfm-test-dev-prod build process, in an Open Notebook&lt;/h1&gt;

&lt;h4&gt;Aims:&lt;/h4&gt;

&lt;p&gt;It was suggested I could document the pumilio test build as an OpenNotebook.
I imagined that I could link this blog to github repo and doco hosted on gh-pages.&lt;/p&gt;

&lt;h4&gt;Methods:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;For ie the emacs html output now goes to &lt;a href=&quot;http://ivanhanigan.github.io/pumilio-bushfm/&quot;&gt;http://ivanhanigan.github.io/pumilio-bushfm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;then collaborators can clone/fork &lt;a href=&quot;https://github.com/ivanhanigan/pumilio-bushfm&quot;&gt;https://github.com/ivanhanigan/pumilio-bushfm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;and comment/complain at &lt;a href=&quot;https://github.com/ivanhanigan/pumilio-bushfm/wiki&quot;&gt;https://github.com/ivanhanigan/pumilio-bushfm/wiki&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Results:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;I did a test build a month ago on an old laptop sitting around, then rebuilt on the Nectar cloud&lt;/li&gt;
&lt;li&gt;Unfortunately I didn't realise that the Nectar VM had mounted /var on to the smaller root partition (the 40GB 2nd disk is on /mnt).&lt;/li&gt;
&lt;li&gt;then when I tried to upload a big sound file it broke :-(&lt;/li&gt;
&lt;li&gt;I did a bit of reading and whilst I began thinking I'd just need to move the mysql datadir via&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sudo nano /etc/mysql/my.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h4&gt;BUT&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;it actually looks like there is a WAV and MP3 file under /var/www/pumilio-2...&lt;/li&gt;
&lt;li&gt;so I think I can &lt;a href=&quot;http://askubuntu.com/questions/39536/how-can-i-store-var-on-a-separate-partition&quot;&gt;just remount /var&lt;/a&gt; onto the larger /mnt secondary disk.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Fri Nov 15 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/pumilio-bushfm-test-dev-prod/</link>
			</item>
		
			<item>
				<title>What Do Scientists Who Write Metadata Use To Do It? And Why?</title>
				<description>&lt;ul&gt;
&lt;li&gt;The extent to which scientists write metadata is probably lower than it ought to be&lt;/li&gt;
&lt;li&gt;The level of metadata written during science projects is probably described generally as 'bare-minimum' and &quot;the minimum needed for one-self to come back to and understand what one did&quot;&lt;/li&gt;
&lt;li&gt;It sometimes seems that even the bare minimum for one-self is not being kept very often&lt;/li&gt;
&lt;li&gt;I argue that the reasons for less-than-adequate metadata can be understood by looking at&lt;/li&gt;
&lt;li&gt;1) the culture of the scienctists displinary background via training&lt;/li&gt;
&lt;li&gt;2) the tools available and&lt;/li&gt;
&lt;li&gt;3) institutional  requirements to produce metadata (both about data or access to data)&lt;/li&gt;
&lt;li&gt;In my ongoing &lt;a href=&quot;http://ivanhanigan.github.io/2013/10/two-main-types-of-data-documentation-workflow/&quot;&gt;series of blog posts I am exploring the tools available&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In this post I just wanted to start the discussion about discipline culture and institutional requirements.&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Discipline Culture&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;I trained in Geography in the age of GIS and this community uses metadata a lot&lt;/li&gt;
&lt;li&gt;Due to the prevalance of the digital map (collection of layers) which is a derivative data output&lt;/li&gt;
&lt;li&gt;Need to know the source of all the layers&lt;/li&gt;
&lt;li&gt;first law of GIS is &quot;garbage in, garbage out&quot;&lt;/li&gt;
&lt;li&gt;I was trained in the ANSLIC standard from the start&lt;/li&gt;
&lt;li&gt;ArcGIS has a tool called ArcCatalog which makes metadata easy to create and view&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;Institutional Requirements&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The ARC and NHMRC say they are going to require more metadata (and even data deposit)&lt;/li&gt;
&lt;li&gt;Restrictions on data access make it necessary to describe at least the metadata around provision agreements, licence, allowable access&lt;/li&gt;
&lt;li&gt;A supporting management level who value the metadata as research output (alongside a peer reviewed paper metadata pales in comparison)&lt;/li&gt;
&lt;li&gt;My old boss used to say &quot;Work Not Published Is Work Not Done&quot;.&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;This reminds me of Approaches and Barriers to Reproducible Research&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;In 2011 BiostatMatt (Matt Shotwell) published &lt;a href=&quot;http://biostatmatt.com/uploads/shotwell-interface-2011.pdf&quot;&gt;a survey of biostatisticians&lt;/a&gt;
VUMC Dept. of Biostatistics to assess:&lt;/li&gt;
&lt;li&gt;the prevalence of fully scripted data analyses&lt;/li&gt;
&lt;li&gt;the prevalence of literate programming practices&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;To assess the perceived barriers to reproducible research the also asked:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;What The biggest obstacle to always reproducibly scripting your work?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;pre&gt;&lt;code&gt;| Barrier                                                  | Staff | Faculty |
|----------------------------------------------------------+-------+---------|
| No signifcant obstacles.                                 |     8 |      10 |
| I havent learned how.                                    |     0 |       0 |
| It takes more time.                                      |     7 |       7 |
| It makes collaboration difficult (eg. file compatibility)|     4 |       2 |
| The software I use doesnt facilitate reproducibility.    |     0 |       0 |
| Its not always necessary for my work to be reproducible. |     2 |       0 |
| Other                                                    |     2 |       1 |
|----------------------------------------------------------+-------+---------|
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;So what about the Approaches and Barriers to Me Writing Metadata?&lt;/h3&gt;

&lt;p&gt;With a sample size of one I asked myself these questions:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;| Q                                                  | A                                                                    |
|----------------------------------------------------+----------------------------------------------------------------------|
| Do I fully document data (to a metadata standard?) | Occasionally, using DDI for high value raw inputs and final products |
| Do I employ data documentation practices           | I use a tool I created to write minimal metadata occasionally        |
| What are the main barriers?                        | takes more time, The software doesnt facilitate, not always necessary|
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Conclusions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The tools need to help write metadata

&lt;ul&gt;
&lt;li&gt;the Institution needs to require metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;References&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Shotwell, M.S. and Alvarez, J.M. 2011. Approaches and Barriers to Reproducible Practices in Biostatistics.
http://biostatmatt.com/uploads/shotwell-interface-2011.pdf&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>Wed Nov 06 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/what-do-scientists-who-write-metadata-use-to-do-it-and-why/</link>
			</item>
		
			<item>
				<title>librarians-and-python</title>
				<description>&lt;p&gt;I stumbled on these posts by &quot;Data Scientist Training for Librarians&quot;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://altbibl.io/dst4l/exploratory-data-analysis-and-statistics-using-pandas-and-matplotlib/&quot;&gt;http://altbibl.io/dst4l/exploratory-data-analysis-and-statistics-using-pandas-and-matplotlib/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://altbibl.io/dst4l/pandas-munging-stats-and-visualization/&quot;&gt;http://altbibl.io/dst4l/pandas-munging-stats-and-visualization/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I;ve been wanting to learn more python.  I don't think it'll be ready for statistical modelling for a while, but I a want to be ready when it is.&lt;/p&gt;

&lt;h4&gt;R Code: get the olive oil dataset&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&quot;pgmm&quot;)
require(pgmm)
data(olive)
write.csv(olive, &quot;~/olive.csv&quot;, row.names = F)
olive &amp;lt;- read.csv(&quot;~/olive.csv&quot;)
names(olive) &amp;lt;- tolower(names(olive))
str(olive)
write.csv(olive, &quot;~/olive.csv&quot;, row.names = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h3&gt;OK now reproduce the example&lt;/h3&gt;

&lt;p&gt;I quite like the histograms from the second example.&lt;/p&gt;

&lt;h4&gt;Code:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;%pylab inline
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import matplotlib.colors as colors

acidlist=['palmitic', 'palmitoleic', 'stearic', 'oleic', 'linoleic', 'linolenic', 'arachidic', 'eicosenoic']
dfsub=df[acidlist].apply(lambda x: x/100.0)
dfsub.head()

rkeys=[1,2,3]
rvals=['South','Sardinia','North']
rmap={e[0]:e[1] for e in zip(rkeys,rvals)}
rmap

fig, axes=plt.subplots(figsize=(10,20), nrows=len(acidlist), ncols=1) # sets up the framework for the graphs. Acidlist is defined elsewhere, and is a list of the acids we’re interested in.
i=0 # Sets a counter to 0

for ax in axes.flatten(): # Starts a loop to go through our plot and render each row

    acid=acidlist[i]
    seriesacid=df[acid] # creates seriesacid and sets it to df[acid], a list of the percent composition of the acid in the current iteration that’s in each olive oil.

    minmax=[seriesacid.min(), seriesacid.max()] # the minimum and maximum values plotted will be the minimum and maximum percentages that we find in the data

    for k,g in df.groupby('region'):  # starts a loop in the loop to plot the values by region
        style = {'histtype':'stepfilled', 'alpha':0.5, 'label':rmap[k], 'ax':ax}
        g[acid].hist(**style)

        ax.set_xlim(minmax)

        ax.set_title(acid)

        ax.grid(False)

        #construct legend
        ax.legend()
    i=i+1 # increments the counter, to move the loop on to the next acid.

    fig.tight_layout()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;p&gt;&lt;img src=&quot;/images/acid.png&quot; alt=&quot;acid.png&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Conclusions&lt;/h3&gt;

&lt;p&gt;I am not sure how to do the transparency but the rest of it would make more sense to me with R&lt;/p&gt;

&lt;p&gt;Will try to reproduce in R for head-to-head shoot out.&lt;/p&gt;
</description>
				<published>Wed Nov 06 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/librarians-and-python/</link>
			</item>
		
			<item>
				<title>handling-survey-data-with-r</title>
				<description>&lt;p&gt;R is generally very good for handling many different data types but&lt;/p&gt;

&lt;h3&gt;R has problems with survey data&lt;/h3&gt;

&lt;p&gt;This post is a stub about what packages Ive found with methods allowing to handle efficiently survey data: handle variable labels, values labels, and retrieve information about missing values&lt;/p&gt;

&lt;h4&gt;Base R:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;## Not run:
require(foreign)
analyte  &amp;lt;- read.spss(filename, to.data.frame=T) 
varslist &amp;lt;- as.data.frame(attributes(analyte)$variable.labels)
# this gives a pretty useful thing to use
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;p&gt;While I was digging around in &lt;a href=&quot;http://mephisto.unige.ch/traminer&quot;&gt;TraMineR&lt;/a&gt; I found this link to Dataset, Emmanuel Rousseaux's package for handling, documenting and describing data sets of survey data.&lt;/p&gt;

&lt;h4&gt;Code:Dataset, a package for handling-survey-data-with-r&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;if(!require(Dataset)) install.packages(&quot;Dataset&quot;, repos=&quot;http://R-Forge.R-project.org&quot;);
require(Dataset)
data(dds)
str(dds)
# cool
description(dds$sexe)
# excellent!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;


&lt;h3&gt;Conclusions&lt;/h3&gt;

&lt;p&gt;I'm sure there are plenty of other approaches.  I'll add them as I find them'&lt;/p&gt;
</description>
				<published>Wed Nov 06 00:00:00 +1100 2013</published>
				<link>http://schamberlain.github.com/2013/11/handling-survey-data-with-r/</link>
			</item>
		
	</channel>
</rss>